{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=60000, imgc=3, imgsz=84, k_qry=15, k_spt=1, meta_lr=0.001, n_way=5, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "init\n",
      "=> loading checkpoint 'mamlfgsmeps4_2.pt'\n",
      "=> loaded checkpoint 'mamlfgsmeps4_2.pt' (epoch 0)\n",
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:800, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (14): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (15): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (16): Parameter containing: [torch.float32 of size 5x800 (GPU 0)]\n",
      "        (17): Parameter containing: [torch.float32 of size 5 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 32901\n",
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n",
      "step: 0 \ttraining acc: [0.14666667 0.33333333 0.36       0.37333333 0.36       0.37333333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05333333]\n",
      "step: 30 \ttraining acc: [0.09333333 0.33333333 0.37333333 0.4        0.38666667 0.38666667]\n",
      "step: 30 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 60 \ttraining acc: [0.36       0.46666667 0.46666667 0.45333333 0.45333333 0.45333333]\n",
      "step: 60 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.16]\n",
      "step: 90 \ttraining acc: [0.09333333 0.66666667 0.73333333 0.73333333 0.73333333 0.73333333]\n",
      "step: 90 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.16]\n",
      "step: 120 \ttraining acc: [0.14666667 0.33333333 0.32       0.30666667 0.32       0.32      ]\n",
      "step: 120 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 150 \ttraining acc: [0.08       0.58666667 0.61333333 0.61333333 0.61333333 0.61333333]\n",
      "step: 150 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17333333]\n",
      "step: 180 \ttraining acc: [0.26666667 0.6        0.62666667 0.66666667 0.66666667 0.68      ]\n",
      "step: 180 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18666667]\n",
      "step: 210 \ttraining acc: [0.10666667 0.44       0.41333333 0.41333333 0.38666667 0.37333333]\n",
      "step: 210 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09333333]\n",
      "step: 240 \ttraining acc: [0.18666667 0.64       0.64       0.64       0.64       0.64      ]\n",
      "step: 240 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14666667]\n",
      "step: 270 \ttraining acc: [0.10666667 0.66666667 0.62666667 0.61333333 0.61333333 0.61333333]\n",
      "step: 270 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.25333333]\n",
      "step: 300 \ttraining acc: [0.09333333 0.44       0.42666667 0.44       0.42666667 0.42666667]\n",
      "step: 300 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06666667]\n"
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "import time\n",
    "\n",
    "#from ANIP import Meta\n",
    "#from metafgsmanil import Meta\n",
    "#from metafgsm import Meta\n",
    "#from MAMLMeta import Meta\n",
    "#from meta import Meta\n",
    "#from Adv_Quer import Meta\n",
    "#from metafgsmnewnew import Meta\n",
    "from metafgsm import Meta\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('../run/aRUB-batched-0.003', comment='aRUB-batched-0.003')\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0] \n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "def main():\n",
    "    \n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 5 * 5])\n",
    "    ]\n",
    "\n",
    "    device = torch.device('cuda:0')\n",
    "    maml = Meta(args, config, device).to(device)\n",
    "    \n",
    "    \n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    filename = 'mamlfgsmeps4_2.pt'\n",
    "    #maml = Meta(args, config).to(device)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        maml.net.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "    \n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('../../dataset/', mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                        k_query=args.k_qry,\n",
    "                        batchsz=10000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../../dataset/', mode='test', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "    tot_step = -1\n",
    "    #for epoch in range(args.epoch//10000):\n",
    "    for epoch in range(15):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "            tot_step = tot_step + 1\n",
    "            if step == 1:\n",
    "                t = time.perf_counter()\n",
    "            if step == 499:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "            if step == 501:\n",
    "                t = time.perf_counter()\n",
    "            if step == 999:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs, accs_adv, loss_q, loss_q_adv = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "                print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "                writer.add_scalar(\"acc/train\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/train\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"loss/train\", loss_q,tot_step)\n",
    "                writer.add_scalar(\"loss_adv/train\", loss_q_adv,tot_step)\n",
    "                state = {'epoch': epoch, 'step': step, 'state_dict': maml.net.state_dict()}\n",
    "                torch.save(state, 'mamlfgsmeps4_2.pt')\n",
    "\n",
    "            if step % 1000 == 0:  # evaluation -> 학습에는 전혀 영향을 주지 않음, copy network를 사용하므로\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                accsadv_all_test = []\n",
    "                accsadvpr_all_test = []\n",
    "                \n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    accs, accs_adv, accs_adv_prior = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "                    accsadv_all_test.append(accs_adv)\n",
    "                    accsadvpr_all_test.append(accs_adv_prior)\n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "                print('Test acc:', accs)\n",
    "                print('Test acc_adv:', accs_adv)\n",
    "                print('Test acc_adv_prior:', accs_adv_prior)\n",
    "                writer.add_scalar(\"acc/test\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/test\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv_prior/test\", accs_adv_prior[-1],tot_step)\n",
    "                if step % 60000==0:\n",
    "                    writer.add_scalar(\"acc/test_epoch\", accs[-1],tot_step//60000)\n",
    "                    writer.add_scalar(\"acc_adv/test_epoch\", accs_adv[-1],tot_step//60000)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=60000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=84)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=1)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=1e-3)\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
