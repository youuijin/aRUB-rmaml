{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=60000, imgc=3, imgsz=28, k_qry=15, k_spt=1, meta_lr=0.003, n_way=5, task_num=32, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "init\n",
      "=> no checkpoint found at 'mamlfgsmeps2_8.pt'\n",
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:128, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.float32 of size 5x128 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.float32 of size 5 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 20229\n",
      "shuffle DB :train, b:4000, 5-way, 1-shot, 15-query, resize:28\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:28\n",
      "step: 0 \ttraining acc: [0.21458333 0.23833333 0.24875    0.24791667 0.25291667 0.25125   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.00458333]\n",
      "Test acc: [0.1938 0.2063 0.2198 0.2234 0.2252 0.2261 0.2281 0.2283 0.2286 0.2292\n",
      " 0.2296]\n",
      "Test acc_adv: [0.003067 0.01694  0.00906  0.005066 0.00453  0.0036   0.003067 0.002666\n",
      " 0.002934 0.0028   0.002666]\n",
      "Test acc_adv_prior: [0.01509  0.08026  0.0407   0.02141  0.01907  0.01506  0.013    0.011086\n",
      " 0.01189  0.01102  0.01037 ]\n",
      "step: 10 \ttraining acc: [0.19666667 0.23583333 0.26416667 0.28083333 0.28375    0.28708333]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.00375]\n",
      "step: 20 \ttraining acc: [0.20625    0.25041667 0.26458333 0.27791667 0.28125    0.2875    ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03166667]\n",
      "step: 30 \ttraining acc: [0.20208333 0.275      0.30208333 0.30458333 0.30458333 0.31125   ]\n",
      "step: 30 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.07]\n",
      "step: 40 \ttraining acc: [0.21583333 0.25958333 0.28291667 0.29375    0.30083333 0.30125   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06916667]\n",
      "step: 50 \ttraining acc: [0.21375    0.26333333 0.29       0.30708333 0.31416667 0.31625   ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08875]\n",
      "step: 60 \ttraining acc: [0.2025     0.27541667 0.30875    0.32916667 0.33       0.33166667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09583333]\n",
      "Test acc: [0.2075 0.2314 0.2472 0.2578 0.262  0.2632 0.2646 0.2664 0.2642 0.2651\n",
      " 0.2678]\n",
      "Test acc_adv: [0.03053 0.05212 0.06506 0.0832  0.09375 0.1011  0.1083  0.11346 0.1163\n",
      " 0.1201  0.1236 ]\n",
      "Test acc_adv_prior: [0.1393 0.2264 0.2627 0.3206 0.3596 0.3835 0.4094 0.427  0.442  0.4534\n",
      " 0.4602]\n",
      "step: 70 \ttraining acc: [0.20916667 0.28041667 0.305      0.30958333 0.31083333 0.31416667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08916667]\n",
      "step: 80 \ttraining acc: [0.20583333 0.29375    0.305      0.30958333 0.31083333 0.31041667]\n",
      "step: 80 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0975]\n",
      "step: 90 \ttraining acc: [0.18875    0.265      0.30333333 0.32125    0.32541667 0.32958333]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0875]\n",
      "step: 100 \ttraining acc: [0.20958333 0.28375    0.3175     0.32708333 0.33041667 0.33333333]\n",
      "step: 100 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1025]\n",
      "step: 110 \ttraining acc: [0.19833333 0.29166667 0.32916667 0.34875    0.34791667 0.34375   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10541667]\n",
      "step: 120 \ttraining acc: [0.16416667 0.23958333 0.27125    0.29041667 0.29333333 0.29708333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08541667]\n",
      "Test acc: [0.1979 0.2274 0.2542 0.261  0.2673 0.2676 0.2695 0.2693 0.2705 0.2727\n",
      " 0.2727]\n",
      "Test acc_adv: [0.0148  0.03146 0.05548 0.0768  0.0961  0.1072  0.116   0.1228  0.1283\n",
      " 0.1309  0.134  ]\n",
      "Test acc_adv_prior: [0.07385 0.1345  0.2151  0.295   0.3606  0.402   0.4312  0.4558  0.4746\n",
      " 0.481   0.492  ]\n",
      "step: 0 \ttraining acc: [0.20083333 0.2725     0.31875    0.32666667 0.33083333 0.3325    ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09958333]\n",
      "Test acc: [0.1963 0.2302 0.2534 0.2634 0.2654 0.2695 0.2705 0.2712 0.2722 0.272\n",
      " 0.2722]\n",
      "Test acc_adv: [0.01733 0.03653 0.05774 0.07825 0.09705 0.1095  0.1173  0.12415 0.131\n",
      " 0.1345  0.1375 ]\n",
      "Test acc_adv_prior: [0.0836 0.1527 0.2249 0.2957 0.3618 0.4023 0.4292 0.4548 0.4778 0.4927\n",
      " 0.5024]\n",
      "step: 10 \ttraining acc: [0.2025     0.27916667 0.3125     0.32       0.33125    0.33666667]\n",
      "step: 10 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0975]\n",
      "step: 20 \ttraining acc: [0.21375    0.27583333 0.30166667 0.30375    0.30833333 0.30916667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08833333]\n",
      "step: 30 \ttraining acc: [0.1975     0.28041667 0.31541667 0.32333333 0.325      0.32208333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08875]\n",
      "step: 40 \ttraining acc: [0.21333333 0.29458333 0.32458333 0.34083333 0.34541667 0.34625   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09666667]\n",
      "step: 50 \ttraining acc: [0.21166667 0.28833333 0.31666667 0.32791667 0.33916667 0.34      ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10625]\n",
      "step: 60 \ttraining acc: [0.22       0.2925     0.31958333 0.31833333 0.3225     0.32333333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09541667]\n",
      "Test acc: [0.2026 0.2395 0.2632 0.265  0.2717 0.2747 0.2769 0.2795 0.282  0.282\n",
      " 0.2837]\n",
      "Test acc_adv: [0.01573 0.04    0.0645  0.08856 0.10376 0.116   0.1257  0.1318  0.1367\n",
      " 0.1401  0.144  ]\n",
      "Test acc_adv_prior: [0.0747 0.1603 0.241  0.3328 0.381  0.4216 0.4521 0.4707 0.4832 0.4956\n",
      " 0.5054]\n",
      "step: 70 \ttraining acc: [0.20791667 0.28958333 0.32458333 0.32875    0.33041667 0.33083333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09083333]\n",
      "step: 80 \ttraining acc: [0.21208333 0.29125    0.31791667 0.32875    0.335      0.335     ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09333333]\n",
      "step: 90 \ttraining acc: [0.20416667 0.29041667 0.32958333 0.34       0.34583333 0.35      ]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10625]\n",
      "step: 100 \ttraining acc: [0.22708333 0.29375    0.32166667 0.32916667 0.33541667 0.33916667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09833333]\n",
      "step: 110 \ttraining acc: [0.17666667 0.245      0.28791667 0.30041667 0.31291667 0.32      ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09041667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 120 \ttraining acc: [0.19208333 0.28541667 0.33       0.34541667 0.34583333 0.3475    ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09708333]\n",
      "Test acc: [0.2012 0.2401 0.267  0.282  0.2808 0.2834 0.2847 0.2869 0.2878 0.2888\n",
      " 0.2903]\n",
      "Test acc_adv: [0.0216  0.03665 0.0584  0.082   0.10144 0.11426 0.124   0.1312  0.1353\n",
      " 0.1401  0.143  ]\n",
      "Test acc_adv_prior: [0.1005 0.1483 0.2158 0.2922 0.364  0.4072 0.4387 0.46   0.4717 0.485\n",
      " 0.4924]\n",
      "step: 0 \ttraining acc: [0.19166667 0.27958333 0.32333333 0.34791667 0.3525     0.35541667]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1125]\n",
      "Test acc: [0.2052 0.2524 0.2732 0.2795 0.2805 0.2812 0.2822 0.2837 0.2832 0.2844\n",
      " 0.285 ]\n",
      "Test acc_adv: [0.0252  0.04694 0.0673  0.0905  0.1113  0.1212  0.1317  0.138   0.143\n",
      " 0.1465  0.1492 ]\n",
      "Test acc_adv_prior: [0.11993 0.1848  0.2434  0.3225  0.3936  0.4275  0.4631  0.483   0.5034\n",
      " 0.513   0.523  ]\n",
      "step: 10 \ttraining acc: [0.19333333 0.26416667 0.30125    0.30333333 0.3075     0.30875   ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09541667]\n",
      "step: 20 \ttraining acc: [0.21       0.28416667 0.32375    0.33333333 0.34       0.34125   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08833333]\n",
      "step: 30 \ttraining acc: [0.20541667 0.31583333 0.33791667 0.35375    0.35666667 0.35791667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10916667]\n",
      "step: 40 \ttraining acc: [0.18541667 0.28541667 0.31666667 0.3325     0.33666667 0.3375    ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09041667]\n",
      "step: 50 \ttraining acc: [0.19083333 0.29       0.32708333 0.34666667 0.35833333 0.36291667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09583333]\n",
      "step: 60 \ttraining acc: [0.19166667 0.27333333 0.31375    0.32291667 0.33083333 0.33458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08458333]\n",
      "Test acc: [0.2067 0.2427 0.265  0.2788 0.2844 0.2844 0.2869 0.2886 0.2903 0.2922\n",
      " 0.2935]\n",
      "Test acc_adv: [0.0164  0.03906 0.05933 0.08264 0.09973 0.11145 0.1217  0.1277  0.1328\n",
      " 0.1383  0.1417 ]\n",
      "Test acc_adv_prior: [0.07715 0.1571  0.221   0.2942  0.3462  0.387   0.4182  0.4365  0.452\n",
      " 0.4683  0.4778 ]\n",
      "step: 70 \ttraining acc: [0.20625    0.3075     0.33958333 0.35625    0.35916667 0.36458333]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.11125]\n",
      "step: 80 \ttraining acc: [0.18333333 0.26041667 0.29666667 0.31208333 0.31875    0.32583333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08666667]\n",
      "step: 90 \ttraining acc: [0.17708333 0.26208333 0.31833333 0.33208333 0.33833333 0.34791667]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.11625]\n",
      "step: 100 \ttraining acc: [0.21916667 0.28125    0.30208333 0.32083333 0.32208333 0.32791667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08583333]\n",
      "step: 110 \ttraining acc: [0.19916667 0.25416667 0.28291667 0.29625    0.3025     0.30958333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07541667]\n",
      "step: 120 \ttraining acc: [0.225      0.29666667 0.32333333 0.3325     0.33833333 0.33708333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09708333]\n",
      "Test acc: [0.2073 0.2507 0.2705 0.279  0.2827 0.2874 0.2874 0.2874 0.2876 0.288\n",
      " 0.2886]\n",
      "Test acc_adv: [0.03787 0.05505 0.07465 0.0944  0.10895 0.1192  0.1278  0.1335  0.1395\n",
      " 0.143   0.146  ]\n",
      "Test acc_adv_prior: [0.1768 0.2126 0.2756 0.34   0.3867 0.4155 0.445  0.4648 0.485  0.4958\n",
      " 0.5054]\n",
      "step: 0 \ttraining acc: [0.21791667 0.28333333 0.33875    0.35416667 0.365      0.37041667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10708333]\n",
      "Test acc: [0.2004 0.2362 0.2656 0.2793 0.2864 0.288  0.2888 0.2883 0.2898 0.2915\n",
      " 0.2913]\n",
      "Test acc_adv: [0.03894 0.05466 0.0727  0.0915  0.10626 0.11865 0.1298  0.1345  0.1398\n",
      " 0.1426  0.1465 ]\n",
      "Test acc_adv_prior: [0.1887 0.2249 0.2705 0.3247 0.3684 0.4124 0.4497 0.4663 0.481  0.4878\n",
      " 0.502 ]\n",
      "step: 10 \ttraining acc: [0.22166667 0.28958333 0.33625    0.35541667 0.35833333 0.35791667]\n",
      "step: 10 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0975]\n",
      "step: 20 \ttraining acc: [0.21583333 0.285      0.31666667 0.3225     0.32791667 0.33083333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10291667]\n",
      "step: 30 \ttraining acc: [0.19625    0.28833333 0.32208333 0.33541667 0.3375     0.33875   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09208333]\n",
      "step: 40 \ttraining acc: [0.225      0.315      0.34666667 0.34958333 0.35791667 0.35958333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12208333]\n",
      "step: 50 \ttraining acc: [0.18666667 0.2675     0.29916667 0.31583333 0.325      0.32625   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08333333]\n",
      "step: 60 \ttraining acc: [0.2125     0.29166667 0.3375     0.35416667 0.35833333 0.36208333]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10625]\n",
      "Test acc: [0.184  0.221  0.2537 0.2686 0.2776 0.282  0.2825 0.2844 0.2856 0.2886\n",
      " 0.2913]\n",
      "Test acc_adv: [0.02747 0.0452  0.0681  0.0904  0.10974 0.11945 0.1282  0.1342  0.1385\n",
      " 0.1418  0.1451 ]\n",
      "Test acc_adv_prior: [0.1414 0.198  0.2668 0.3335 0.3914 0.4167 0.448  0.467  0.4807 0.4885\n",
      " 0.4956]\n",
      "step: 70 \ttraining acc: [0.22875    0.29208333 0.32041667 0.33875    0.34041667 0.34458333]\n",
      "step: 70 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0825]\n",
      "step: 80 \ttraining acc: [0.18916667 0.25041667 0.2975     0.3175     0.32208333 0.33416667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07958333]\n",
      "step: 90 \ttraining acc: [0.19708333 0.26083333 0.30791667 0.32166667 0.32416667 0.32291667]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0775]\n",
      "step: 100 \ttraining acc: [0.20333333 0.325      0.35833333 0.37       0.3775     0.37791667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11541667]\n",
      "step: 110 \ttraining acc: [0.19375    0.29       0.33625    0.35791667 0.36375    0.36541667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10791667]\n",
      "step: 120 \ttraining acc: [0.185      0.28833333 0.33166667 0.35083333 0.35166667 0.35375   ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10583333]\n",
      "Test acc: [0.2078 0.2576 0.2874 0.2954 0.2983 0.3027 0.3035 0.3037 0.305  0.3054\n",
      " 0.3047]\n",
      "Test acc_adv: [0.01813 0.04547 0.07385 0.0924  0.11053 0.1217  0.1312  0.1356  0.1407\n",
      " 0.1447  0.1483 ]\n",
      "Test acc_adv_prior: [0.07904 0.1708  0.25    0.3044  0.3633  0.3948  0.4248  0.4377  0.4539\n",
      " 0.4658  0.4792 ]\n",
      "step: 0 \ttraining acc: [0.19875    0.31625    0.34541667 0.36166667 0.36583333 0.36916667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09666667]\n",
      "Test acc: [0.1923 0.248  0.278  0.2854 0.2913 0.2935 0.2983 0.3015 0.3027 0.3025\n",
      " 0.3032]\n",
      "Test acc_adv: [0.01186 0.03894 0.0688  0.0916  0.11066 0.1229  0.1304  0.1356  0.1392\n",
      " 0.1422  0.1454 ]\n",
      "Test acc_adv_prior: [0.06055 0.1571  0.2426  0.3147  0.3728  0.412   0.432   0.444   0.454\n",
      " 0.4636  0.4724 ]\n",
      "step: 10 \ttraining acc: [0.20666667 0.30125    0.3475     0.36333333 0.37583333 0.38083333]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10875]\n",
      "step: 20 \ttraining acc: [0.22125    0.32416667 0.3675     0.37625    0.38208333 0.38583333]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1125]\n",
      "step: 30 \ttraining acc: [0.19541667 0.29125    0.31958333 0.34166667 0.34125    0.33958333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 40 \ttraining acc: [0.20541667 0.29958333 0.3325     0.34166667 0.34833333 0.34875   ]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50 \ttraining acc: [0.19375    0.3225     0.36375    0.37833333 0.38458333 0.39166667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10791667]\n",
      "step: 60 \ttraining acc: [0.16958333 0.28333333 0.345      0.36833333 0.37166667 0.37625   ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10791667]\n",
      "Test acc: [0.193  0.2524 0.2861 0.2964 0.3044 0.306  0.3098 0.3127 0.3142 0.3154\n",
      " 0.316 ]\n",
      "Test acc_adv: [0.02573 0.05267 0.07495 0.09546 0.1112  0.1211  0.127   0.1317  0.1364\n",
      " 0.1385  0.1406 ]\n",
      "Test acc_adv_prior: [0.1265 0.2019 0.2576 0.3186 0.3616 0.3926 0.4062 0.4187 0.431  0.4346\n",
      " 0.4402]\n",
      "step: 70 \ttraining acc: [0.2075     0.27333333 0.30333333 0.32       0.32208333 0.32166667]\n",
      "step: 70 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0775]\n",
      "step: 80 \ttraining acc: [0.19041667 0.28041667 0.33416667 0.35708333 0.36625    0.37666667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10791667]\n",
      "step: 90 \ttraining acc: [0.18333333 0.29       0.33666667 0.35166667 0.35333333 0.35791667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10083333]\n",
      "step: 100 \ttraining acc: [0.21041667 0.29       0.32541667 0.34       0.34916667 0.36041667]\n",
      "step: 100 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.105]\n",
      "step: 110 \ttraining acc: [0.21083333 0.30458333 0.36458333 0.3775     0.38208333 0.38333333]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.11875]\n",
      "step: 120 \ttraining acc: [0.19375    0.30166667 0.34125    0.37208333 0.38       0.38625   ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09416667]\n",
      "Test acc: [0.1986 0.2642 0.2969 0.31   0.3157 0.318  0.3206 0.3203 0.3208 0.3225\n",
      " 0.3245]\n",
      "Test acc_adv: [0.03348 0.05707 0.08545 0.10815 0.12225 0.1305  0.1373  0.1421  0.1443\n",
      " 0.1483  0.1508 ]\n",
      "Test acc_adv_prior: [0.1602 0.2144 0.29   0.3467 0.386  0.4058 0.4263 0.4426 0.4475 0.4573\n",
      " 0.461 ]\n",
      "step: 0 \ttraining acc: [0.18416667 0.32208333 0.36958333 0.38208333 0.38291667 0.38291667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09791667]\n",
      "Test acc: [0.1978 0.2778 0.3054 0.3162 0.322  0.3245 0.3247 0.3264 0.3271 0.326\n",
      " 0.327 ]\n",
      "Test acc_adv: [0.0184  0.05267 0.08545 0.1116  0.1261  0.1349  0.1403  0.1447  0.1503\n",
      " 0.1517  0.1533 ]\n",
      "Test acc_adv_prior: [0.0816 0.1804 0.274  0.35   0.3894 0.4148 0.4302 0.4412 0.4563 0.4622\n",
      " 0.4646]\n",
      "step: 10 \ttraining acc: [0.18166667 0.30208333 0.35625    0.36791667 0.37416667 0.37708333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10041667]\n",
      "step: 20 \ttraining acc: [0.19083333 0.32666667 0.36791667 0.375      0.375      0.37625   ]\n",
      "step: 20 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.09]\n",
      "step: 30 \ttraining acc: [0.20083333 0.3075     0.3425     0.36125    0.36416667 0.36416667]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09875]\n",
      "step: 40 \ttraining acc: [0.22333333 0.31125    0.35541667 0.36041667 0.36583333 0.37333333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 50 \ttraining acc: [0.19208333 0.29291667 0.35041667 0.36958333 0.37833333 0.37666667]\n",
      "step: 50 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.095]\n",
      "step: 60 \ttraining acc: [0.17291667 0.28083333 0.325      0.34958333 0.35833333 0.36708333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08458333]\n",
      "Test acc: [0.2034 0.2593 0.293  0.3062 0.3127 0.3135 0.3157 0.3176 0.3179 0.3206\n",
      " 0.3213]\n",
      "Test acc_adv: [0.03308 0.06186 0.0852  0.1047  0.1181  0.1293  0.1338  0.1368  0.1387\n",
      " 0.1403  0.139  ]\n",
      "Test acc_adv_prior: [0.1593 0.2378 0.289  0.3374 0.3745 0.4082 0.418  0.4248 0.4304 0.4307\n",
      " 0.4263]\n",
      "step: 70 \ttraining acc: [0.20833333 0.32625    0.36625    0.38208333 0.38791667 0.39083333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11666667]\n",
      "step: 80 \ttraining acc: [0.18666667 0.295      0.34041667 0.35458333 0.35833333 0.36333333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09625]\n",
      "step: 90 \ttraining acc: [0.21541667 0.32375    0.36541667 0.37375    0.37541667 0.38041667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11791667]\n",
      "step: 100 \ttraining acc: [0.2075     0.3475     0.39166667 0.3975     0.405      0.40833333]\n",
      "step: 100 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.105]\n",
      "step: 110 \ttraining acc: [0.20666667 0.34416667 0.3825     0.39791667 0.39458333 0.40041667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10416667]\n",
      "step: 120 \ttraining acc: [0.18916667 0.29583333 0.34625    0.36583333 0.38       0.3825    ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11166667]\n",
      "Test acc: [0.2157 0.2798 0.3057 0.314  0.3184 0.3232 0.327  0.3303 0.331  0.3315\n",
      " 0.3306]\n",
      "Test acc_adv: [0.0324  0.0736  0.10144 0.12225 0.133   0.141   0.1433  0.1456  0.1483\n",
      " 0.1493  0.1493 ]\n",
      "Test acc_adv_prior: [0.1493 0.2563 0.329  0.3853 0.4158 0.4324 0.4353 0.4365 0.4458 0.4468\n",
      " 0.4478]\n",
      "step: 0 \ttraining acc: [0.19208333 0.29       0.34583333 0.3725     0.38166667 0.38833333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10833333]\n",
      "Test acc: [0.1819 0.246  0.298  0.315  0.3186 0.3264 0.3274 0.3284 0.329  0.3284\n",
      " 0.33  ]\n",
      "Test acc_adv: [0.0376  0.06256 0.09064 0.1148  0.1293  0.1396  0.1436  0.1473  0.1492\n",
      " 0.1493  0.1505 ]\n",
      "Test acc_adv_prior: [0.1996 0.2417 0.2944 0.3582 0.3972 0.4204 0.4314 0.442  0.4465 0.4495\n",
      " 0.451 ]\n",
      "step: 10 \ttraining acc: [0.20166667 0.31708333 0.36458333 0.38291667 0.39416667 0.39916667]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10375]\n",
      "step: 20 \ttraining acc: [0.20916667 0.3225     0.35875    0.36583333 0.37541667 0.38333333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09708333]\n",
      "step: 30 \ttraining acc: [0.20416667 0.31291667 0.37166667 0.38583333 0.38916667 0.39416667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11541667]\n",
      "step: 40 \ttraining acc: [0.21458333 0.35       0.38791667 0.40125    0.40625    0.40875   ]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1075]\n",
      "step: 50 \ttraining acc: [0.2025     0.33625    0.37791667 0.38916667 0.39       0.39125   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10458333]\n",
      "step: 60 \ttraining acc: [0.19666667 0.32541667 0.36208333 0.37291667 0.3775     0.38125   ]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1125]\n",
      "Test acc: [0.1975 0.282  0.3188 0.334  0.3376 0.3403 0.3408 0.3408 0.3413 0.3413\n",
      " 0.3413]\n",
      "Test acc_adv: [0.02293 0.06506 0.1     0.12384 0.1371  0.1454  0.1484  0.1516  0.1534\n",
      " 0.1536  0.1549 ]\n",
      "Test acc_adv_prior: [0.1136 0.2207 0.306  0.3616 0.3984 0.4172 0.4265 0.4346 0.4402 0.4404\n",
      " 0.446 ]\n",
      "step: 70 \ttraining acc: [0.19916667 0.35791667 0.40583333 0.40791667 0.4125     0.41833333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11041667]\n",
      "step: 80 \ttraining acc: [0.19875    0.33291667 0.36916667 0.37958333 0.37625    0.38166667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10708333]\n",
      "step: 90 \ttraining acc: [0.21708333 0.36       0.40041667 0.41166667 0.41416667 0.41333333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10916667]\n",
      "step: 100 \ttraining acc: [0.1875     0.31583333 0.38375    0.39083333 0.39875    0.40166667]\n",
      "step: 100 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0875]\n",
      "step: 110 \ttraining acc: [0.20833333 0.33833333 0.365      0.3825     0.39416667 0.39708333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10541667]\n",
      "step: 120 \ttraining acc: [0.17625    0.30583333 0.3525     0.37333333 0.37958333 0.37791667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08791667]\n",
      "Test acc: [0.2042 0.29   0.3162 0.3289 0.3345 0.337  0.3372 0.3352 0.3357 0.3374\n",
      " 0.3389]\n",
      "Test acc_adv: [0.0272  0.0717  0.10706 0.12305 0.1328  0.1406  0.1436  0.1449  0.1456\n",
      " 0.147   0.1471 ]\n",
      "Test acc_adv_prior: [0.1273 0.239  0.3313 0.3677 0.391  0.4133 0.4202 0.4263 0.4272 0.429\n",
      " 0.427 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.19583333 0.34083333 0.3825     0.38541667 0.38333333 0.38875   ]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1125]\n",
      "Test acc: [0.2124 0.3    0.333  0.341  0.3462 0.349  0.3489 0.349  0.3489 0.3489\n",
      " 0.3484]\n",
      "Test acc_adv: [0.03   0.0764 0.1111 0.1316 0.1398 0.1465 0.149  0.1509 0.1504 0.1526\n",
      " 0.1517]\n",
      "Test acc_adv_prior: [0.1326 0.2443 0.3218 0.3757 0.3948 0.4119 0.4197 0.4258 0.4246 0.4314\n",
      " 0.4292]\n",
      "step: 10 \ttraining acc: [0.21458333 0.35916667 0.39083333 0.39458333 0.39916667 0.4025    ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10666667]\n",
      "step: 20 \ttraining acc: [0.2        0.35541667 0.38708333 0.39083333 0.395      0.40166667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09416667]\n",
      "step: 30 \ttraining acc: [0.21666667 0.34708333 0.37958333 0.38541667 0.39166667 0.39166667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08583333]\n",
      "step: 40 \ttraining acc: [0.20291667 0.32791667 0.38208333 0.39833333 0.40125    0.40375   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09041667]\n",
      "step: 50 \ttraining acc: [0.18625    0.30875    0.34791667 0.36291667 0.36458333 0.36833333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09291667]\n",
      "step: 60 \ttraining acc: [0.19541667 0.36708333 0.40333333 0.40916667 0.415      0.42      ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09916667]\n",
      "Test acc: [0.195  0.2913 0.3284 0.34   0.348  0.3508 0.353  0.3538 0.3538 0.3542\n",
      " 0.3545]\n",
      "Test acc_adv: [0.0356 0.0895 0.1244 0.1392 0.1472 0.1489 0.1503 0.1511 0.1503 0.1504\n",
      " 0.1494]\n",
      "Test acc_adv_prior: [0.1754 0.2888 0.3638 0.3953 0.4111 0.4124 0.414  0.418  0.4165 0.4167\n",
      " 0.415 ]\n",
      "step: 70 \ttraining acc: [0.20625    0.33833333 0.37416667 0.37833333 0.37916667 0.38208333]\n",
      "step: 70 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.095]\n",
      "step: 80 \ttraining acc: [0.16916667 0.30666667 0.36916667 0.38666667 0.39166667 0.3925    ]\n",
      "step: 80 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0925]\n",
      "step: 90 \ttraining acc: [0.215      0.32833333 0.36958333 0.37708333 0.38041667 0.38166667]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0975]\n",
      "step: 100 \ttraining acc: [0.18625    0.30333333 0.3575     0.3675     0.37208333 0.37333333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08916667]\n",
      "step: 110 \ttraining acc: [0.20166667 0.31708333 0.37208333 0.38041667 0.38541667 0.38416667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08791667]\n",
      "step: 120 \ttraining acc: [0.19833333 0.36166667 0.39083333 0.3875     0.38875    0.39208333]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09375]\n",
      "Test acc: [0.1992 0.3035 0.3354 0.3413 0.3445 0.3472 0.3489 0.3484 0.348  0.348\n",
      " 0.3484]\n",
      "Test acc_adv: [0.01666 0.0817  0.11615 0.1327  0.1388  0.143   0.1428  0.143   0.1433\n",
      " 0.1432  0.1431 ]\n",
      "Test acc_adv_prior: [0.0854 0.2598 0.3408 0.383  0.397  0.4084 0.4058 0.4065 0.4077 0.4082\n",
      " 0.4072]\n",
      "step: 0 \ttraining acc: [0.19833333 0.34125    0.36416667 0.37166667 0.37375    0.37625   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "Test acc: [0.2052 0.3098 0.3386 0.348  0.3489 0.3506 0.3499 0.3503 0.3538 0.3545\n",
      " 0.3547]\n",
      "Test acc_adv: [0.0316  0.08453 0.1156  0.13    0.135   0.1365  0.1382  0.1383  0.1387\n",
      " 0.1368  0.1392 ]\n",
      "Test acc_adv_prior: [0.1458 0.2651 0.332  0.3652 0.3796 0.3826 0.3872 0.3875 0.3845 0.3784\n",
      " 0.3853]\n",
      "step: 10 \ttraining acc: [0.18625    0.37625    0.40958333 0.42291667 0.42708333 0.43125   ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10458333]\n",
      "step: 20 \ttraining acc: [0.19375    0.33958333 0.37333333 0.37583333 0.38083333 0.3825    ]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0875]\n",
      "step: 30 \ttraining acc: [0.20416667 0.3625     0.38041667 0.38958333 0.38666667 0.38666667]\n",
      "step: 30 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.095]\n",
      "step: 40 \ttraining acc: [0.185      0.35833333 0.40666667 0.41541667 0.4225     0.425     ]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09375]\n",
      "step: 50 \ttraining acc: [0.20375    0.34791667 0.38333333 0.39208333 0.40208333 0.40125   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09583333]\n",
      "step: 60 \ttraining acc: [0.20916667 0.35666667 0.37875    0.38541667 0.3925     0.39458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07958333]\n",
      "Test acc: [0.2078 0.3184 0.3481 0.354  0.3577 0.3591 0.3596 0.3596 0.3586 0.359\n",
      " 0.3577]\n",
      "Test acc_adv: [0.02133 0.0851  0.11505 0.1321  0.1372  0.1405  0.144   0.1437  0.1422\n",
      " 0.1411  0.1412 ]\n",
      "Test acc_adv_prior: [0.09814 0.259   0.324   0.364   0.3765  0.384   0.3933  0.392   0.3884\n",
      " 0.3845  0.387  ]\n",
      "step: 70 \ttraining acc: [0.19708333 0.385      0.42125    0.4425     0.45333333 0.45791667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11291667]\n",
      "step: 80 \ttraining acc: [0.22208333 0.3725     0.415      0.43416667 0.43583333 0.43666667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10083333]\n",
      "step: 90 \ttraining acc: [0.21041667 0.39083333 0.41583333 0.42708333 0.43291667 0.43333333]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08875]\n",
      "step: 100 \ttraining acc: [0.19708333 0.36708333 0.40708333 0.42       0.42625    0.43      ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09541667]\n",
      "step: 110 \ttraining acc: [0.22375    0.34916667 0.38916667 0.40166667 0.41416667 0.41833333]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0825]\n",
      "step: 120 \ttraining acc: [0.21125    0.36916667 0.395      0.4        0.40625    0.4125    ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07958333]\n",
      "Test acc: [0.2    0.3123 0.3398 0.3474 0.3467 0.3472 0.3486 0.3474 0.3472 0.3474\n",
      " 0.3484]\n",
      "Test acc_adv: [0.0288  0.08295 0.1149  0.12494 0.1296  0.13    0.132   0.132   0.1312\n",
      " 0.1316  0.131  ]\n",
      "Test acc_adv_prior: [0.1324 0.2595 0.3293 0.3477 0.3643 0.365  0.3704 0.3716 0.3699 0.3706\n",
      " 0.3682]\n",
      "step: 0 \ttraining acc: [0.1925     0.36166667 0.41458333 0.4225     0.42458333 0.4275    ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10833333]\n",
      "Test acc: [0.1881 0.2646 0.3196 0.3323 0.3408 0.3472 0.3503 0.3523 0.3538 0.3547\n",
      " 0.3545]\n",
      "Test acc_adv: [0.04947 0.0925  0.1208  0.1365  0.1375  0.1383  0.1382  0.1376  0.1372\n",
      " 0.1344  0.136  ]\n",
      "Test acc_adv_prior: [0.2595 0.344  0.3733 0.4055 0.3992 0.3943 0.3892 0.3857 0.3823 0.3726\n",
      " 0.3774]\n",
      "step: 10 \ttraining acc: [0.18666667 0.35833333 0.40166667 0.40708333 0.41333333 0.41416667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06833333]\n",
      "step: 20 \ttraining acc: [0.195      0.40375    0.42541667 0.43166667 0.43166667 0.43375   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10458333]\n",
      "step: 30 \ttraining acc: [0.20458333 0.38166667 0.40125    0.41916667 0.42375    0.42666667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08208333]\n",
      "step: 40 \ttraining acc: [0.19708333 0.37583333 0.42333333 0.43666667 0.4375     0.44125   ]\n",
      "step: 40 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.09]\n",
      "step: 50 \ttraining acc: [0.18166667 0.35958333 0.415      0.42708333 0.43458333 0.43666667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08708333]\n",
      "step: 60 \ttraining acc: [0.20416667 0.3475     0.38541667 0.40041667 0.40875    0.41583333]\n",
      "step: 60 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.095]\n",
      "Test acc: [0.2025 0.3035 0.3345 0.3413 0.3452 0.3472 0.3486 0.349  0.3494 0.3496\n",
      " 0.3496]\n",
      "Test acc_adv: [0.04187 0.08826 0.1108  0.12    0.1257  0.1257  0.1251  0.1255  0.12494\n",
      " 0.1245  0.124  ]\n",
      "Test acc_adv_prior: [0.1989 0.2822 0.324  0.3418 0.3564 0.353  0.3513 0.3523 0.3494 0.3486\n",
      " 0.3489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 70 \ttraining acc: [0.17833333 0.35       0.39166667 0.39791667 0.40583333 0.41125   ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08291667]\n",
      "step: 80 \ttraining acc: [0.19791667 0.38208333 0.41625    0.4275     0.42833333 0.43      ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08708333]\n",
      "step: 90 \ttraining acc: [0.20875    0.35791667 0.39833333 0.40875    0.41375    0.41583333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07458333]\n",
      "step: 100 \ttraining acc: [0.18375    0.34583333 0.37875    0.39833333 0.40291667 0.4075    ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07583333]\n",
      "step: 110 \ttraining acc: [0.19875    0.37416667 0.40333333 0.41166667 0.41125    0.40833333]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08125]\n",
      "step: 120 \ttraining acc: [0.21416667 0.35416667 0.39041667 0.39458333 0.39916667 0.40083333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08458333]\n",
      "Test acc: [0.1969 0.3032 0.3394 0.346  0.3503 0.3506 0.3499 0.3503 0.3496 0.3484\n",
      " 0.348 ]\n",
      "Test acc_adv: [0.03174 0.094   0.11334 0.1235  0.128   0.1276  0.1295  0.1304  0.1298\n",
      " 0.1298  0.1305 ]\n",
      "Test acc_adv_prior: [0.1522 0.3052 0.328  0.349  0.3582 0.3564 0.3613 0.363  0.3623 0.363\n",
      " 0.3667]\n",
      "step: 0 \ttraining acc: [0.18666667 0.34125    0.36333333 0.3725     0.37916667 0.37916667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07791667]\n",
      "Test acc: [0.2024 0.326  0.3533 0.3584 0.36   0.36   0.3608 0.3625 0.3618 0.362\n",
      " 0.3606]\n",
      "Test acc_adv: [0.02187 0.0884  0.1183  0.1277  0.1316  0.1323  0.1299  0.1295  0.129\n",
      " 0.1278  0.1288 ]\n",
      "Test acc_adv_prior: [0.10065 0.258   0.3254  0.3464  0.3572  0.3596  0.352   0.3481  0.3484\n",
      " 0.3442  0.349  ]\n",
      "step: 10 \ttraining acc: [0.225      0.385      0.41875    0.43416667 0.43416667 0.43875   ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09666667]\n",
      "step: 20 \ttraining acc: [0.2025     0.39958333 0.42125    0.42791667 0.42625    0.42583333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 30 \ttraining acc: [0.2075     0.38958333 0.425      0.4325     0.4375     0.4375    ]\n",
      "step: 30 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0925]\n",
      "step: 40 \ttraining acc: [0.20791667 0.38416667 0.4275     0.43166667 0.44333333 0.44625   ]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09125]\n",
      "step: 50 \ttraining acc: [0.21       0.36208333 0.40458333 0.4125     0.41666667 0.41833333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08333333]\n",
      "step: 60 \ttraining acc: [0.22083333 0.40458333 0.44666667 0.455      0.45583333 0.45791667]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0925]\n",
      "Test acc: [0.2153 0.3386 0.3516 0.3564 0.3567 0.358  0.359  0.359  0.3582 0.358\n",
      " 0.3591]\n",
      "Test acc_adv: [0.0296 0.1005 0.1285 0.1312 0.1318 0.1289 0.1266 0.1261 0.1244 0.1256\n",
      " 0.1247]\n",
      "Test acc_adv_prior: [0.1332 0.2878 0.3564 0.3584 0.3604 0.3513 0.3428 0.341  0.338  0.341\n",
      " 0.3386]\n",
      "step: 70 \ttraining acc: [0.19375    0.37458333 0.40583333 0.42       0.42958333 0.43333333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08791667]\n",
      "step: 80 \ttraining acc: [0.20291667 0.33666667 0.36291667 0.37833333 0.38333333 0.38708333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06833333]\n",
      "step: 90 \ttraining acc: [0.21125    0.41875    0.44791667 0.45625    0.45875    0.45541667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10041667]\n",
      "step: 100 \ttraining acc: [0.20583333 0.37625    0.40125    0.40958333 0.41541667 0.42125   ]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06875]\n",
      "step: 110 \ttraining acc: [0.20208333 0.37833333 0.41416667 0.42166667 0.425      0.42916667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08833333]\n",
      "step: 120 \ttraining acc: [0.20458333 0.38375    0.42041667 0.43458333 0.43291667 0.43458333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08083333]\n",
      "Test acc: [0.2134 0.3264 0.3574 0.3596 0.3643 0.366  0.3667 0.367  0.3672 0.3662\n",
      " 0.3665]\n",
      "Test acc_adv: [0.0384  0.0964  0.11615 0.12427 0.1274  0.1287  0.127   0.1267  0.1262\n",
      " 0.1274  0.127  ]\n",
      "Test acc_adv_prior: [0.1754 0.286  0.3176 0.3389 0.3445 0.347  0.3398 0.3403 0.3381 0.3445\n",
      " 0.341 ]\n",
      "step: 0 \ttraining acc: [0.175      0.37916667 0.41958333 0.43833333 0.44541667 0.44541667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08958333]\n",
      "Test acc: [0.2026 0.3333 0.3533 0.3604 0.364  0.3628 0.3635 0.3638 0.3628 0.3635\n",
      " 0.3618]\n",
      "Test acc_adv: [0.02573 0.0924  0.1201  0.1268  0.1283  0.1278  0.1293  0.1284  0.1259\n",
      " 0.1257  0.12415]\n",
      "Test acc_adv_prior: [0.1172 0.2695 0.3306 0.3445 0.3442 0.3442 0.3472 0.3455 0.3386 0.337\n",
      " 0.334 ]\n",
      "step: 10 \ttraining acc: [0.20208333 0.3825     0.41125    0.415      0.41666667 0.41208333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08458333]\n",
      "step: 20 \ttraining acc: [0.21333333 0.40875    0.43208333 0.43666667 0.44416667 0.44      ]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07625]\n",
      "step: 30 \ttraining acc: [0.19375    0.36833333 0.38666667 0.39166667 0.39416667 0.39666667]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08625]\n",
      "step: 40 \ttraining acc: [0.17791667 0.34416667 0.38041667 0.3925     0.39375    0.4       ]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06125]\n",
      "step: 50 \ttraining acc: [0.20958333 0.37208333 0.41833333 0.42875    0.43625    0.43416667]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07625]\n",
      "step: 60 \ttraining acc: [0.19958333 0.39416667 0.42791667 0.43958333 0.44708333 0.45083333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07708333]\n",
      "Test acc: [0.2036 0.3157 0.3518 0.358  0.361  0.3616 0.3628 0.3616 0.3625 0.362\n",
      " 0.3608]\n",
      "Test acc_adv: [0.04785 0.1013  0.1191  0.1251  0.12305 0.1216  0.1188  0.118   0.1164\n",
      " 0.1155  0.11456]\n",
      "Test acc_adv_prior: [0.2301 0.3096 0.3315 0.343  0.3342 0.3298 0.3206 0.318  0.3142 0.3105\n",
      " 0.3088]\n",
      "step: 70 \ttraining acc: [0.22125    0.39708333 0.42458333 0.435      0.44       0.43875   ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07375]\n",
      "step: 80 \ttraining acc: [0.17833333 0.3475     0.39875    0.415      0.4225     0.42833333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 90 \ttraining acc: [0.21166667 0.38541667 0.44       0.455      0.46208333 0.45708333]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09375]\n",
      "step: 100 \ttraining acc: [0.21958333 0.36833333 0.405      0.415      0.41958333 0.425     ]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.08375]\n",
      "step: 110 \ttraining acc: [0.20208333 0.4125     0.44916667 0.46083333 0.46666667 0.46791667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 120 \ttraining acc: [0.19666667 0.36666667 0.40916667 0.41791667 0.41625    0.41791667]\n",
      "step: 120 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.075]\n",
      "Test acc: [0.2051 0.327  0.3604 0.3665 0.3665 0.368  0.3691 0.3696 0.37   0.3691\n",
      " 0.3696]\n",
      "Test acc_adv: [0.04706 0.09985 0.1163  0.1199  0.11786 0.1175  0.11584 0.1155  0.1164\n",
      " 0.11615 0.11615]\n",
      "Test acc_adv_prior: [0.2148 0.2974 0.3118 0.3162 0.3113 0.3086 0.303  0.3005 0.303  0.304\n",
      " 0.3025]\n",
      "step: 0 \ttraining acc: [0.20958333 0.36666667 0.39125    0.39625    0.40208333 0.40166667]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0675]\n",
      "Test acc: [0.2058 0.3213 0.3535 0.3652 0.366  0.3672 0.3677 0.3677 0.3682 0.367\n",
      " 0.3662]\n",
      "Test acc_adv: [0.03214 0.09656 0.1144  0.1149  0.1144  0.1128  0.11426 0.1147  0.1136\n",
      " 0.114   0.11346]\n",
      "Test acc_adv_prior: [0.1516 0.2961 0.3164 0.3088 0.3062 0.3018 0.305  0.3074 0.3037 0.3057\n",
      " 0.3064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 \ttraining acc: [0.18458333 0.40375    0.43583333 0.44916667 0.45416667 0.45791667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07958333]\n",
      "step: 20 \ttraining acc: [0.19833333 0.39541667 0.41208333 0.42666667 0.4275     0.42625   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06708333]\n",
      "step: 30 \ttraining acc: [0.21708333 0.4175     0.43958333 0.44458333 0.44291667 0.44125   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09333333]\n",
      "step: 40 \ttraining acc: [0.19375    0.37083333 0.42125    0.43791667 0.44166667 0.44333333]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0625]\n",
      "step: 50 \ttraining acc: [0.19833333 0.38041667 0.4        0.41041667 0.41166667 0.41541667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08041667]\n",
      "step: 60 \ttraining acc: [0.21791667 0.38583333 0.41208333 0.41916667 0.42291667 0.42458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04291667]\n",
      "Test acc: [0.2062 0.3315 0.3633 0.3718 0.3723 0.3735 0.3735 0.3728 0.3723 0.3733\n",
      " 0.3735]\n",
      "Test acc_adv: [0.04492 0.1093  0.1165  0.11774 0.1172  0.1144  0.11053 0.1103  0.1085\n",
      " 0.106   0.1059 ]\n",
      "Test acc_adv_prior: [0.2169 0.3215 0.3103 0.3052 0.303  0.2954 0.2856 0.2852 0.2817 0.273\n",
      " 0.2722]\n",
      "step: 70 \ttraining acc: [0.19416667 0.37541667 0.39333333 0.39625    0.39583333 0.39541667]\n",
      "step: 70 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.06]\n",
      "step: 80 \ttraining acc: [0.2025     0.43208333 0.46333333 0.47       0.4775     0.47333333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09375]\n",
      "step: 90 \ttraining acc: [0.195      0.39416667 0.40833333 0.42       0.42041667 0.42416667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08166667]\n",
      "step: 100 \ttraining acc: [0.20458333 0.36791667 0.3875     0.38541667 0.38916667 0.38458333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04416667]\n",
      "step: 110 \ttraining acc: [0.20291667 0.38875    0.41333333 0.42333333 0.43041667 0.43208333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07208333]\n",
      "step: 120 \ttraining acc: [0.16708333 0.42541667 0.45041667 0.4625     0.46541667 0.46291667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07333333]\n",
      "Test acc: [0.198  0.3347 0.3625 0.3677 0.3708 0.3735 0.3738 0.3733 0.371  0.371\n",
      " 0.3723]\n",
      "Test acc_adv: [0.02853 0.1091  0.12335 0.1248  0.12134 0.1208  0.1188  0.1184  0.1163\n",
      " 0.11707 0.11536]\n",
      "Test acc_adv_prior: [0.1327 0.316  0.3325 0.3323 0.3186 0.3147 0.3103 0.3086 0.306  0.3076\n",
      " 0.302 ]\n",
      "step: 0 \ttraining acc: [0.20458333 0.43458333 0.45916667 0.45666667 0.4575     0.46208333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09416667]\n",
      "Test acc: [0.1954 0.3213 0.3516 0.3572 0.359  0.3596 0.3616 0.3618 0.3608 0.3616\n",
      " 0.361 ]\n",
      "Test acc_adv: [0.03748 0.0996  0.1181  0.1173  0.1127  0.1083  0.106   0.1021  0.0996\n",
      " 0.0985  0.0992 ]\n",
      "Test acc_adv_prior: [0.1819 0.298  0.3274 0.321  0.306  0.2947 0.2861 0.2742 0.2683 0.2656\n",
      " 0.2664]\n",
      "step: 10 \ttraining acc: [0.20125    0.375      0.41708333 0.43458333 0.44625    0.4525    ]\n",
      "step: 10 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0825]\n",
      "step: 20 \ttraining acc: [0.20291667 0.39541667 0.42291667 0.42916667 0.43125    0.43166667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05416667]\n",
      "step: 30 \ttraining acc: [0.20541667 0.41958333 0.45458333 0.46625    0.46875    0.47375   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08166667]\n",
      "step: 40 \ttraining acc: [0.18791667 0.43333333 0.45708333 0.4625     0.46416667 0.46875   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09208333]\n",
      "step: 50 \ttraining acc: [0.21333333 0.40125    0.41875    0.42166667 0.4275     0.42125   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06458333]\n",
      "step: 60 \ttraining acc: [0.21541667 0.39166667 0.40708333 0.40791667 0.40791667 0.41041667]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "Test acc: [0.2078 0.3303 0.3564 0.3647 0.3662 0.3652 0.363  0.3652 0.3638 0.364\n",
      " 0.365 ]\n",
      "Test acc_adv: [0.03146 0.0959  0.10547 0.1112  0.1101  0.1076  0.1067  0.1064  0.10693\n",
      " 0.1049  0.1052 ]\n",
      "Test acc_adv_prior: [0.1454 0.2834 0.2893 0.2976 0.2932 0.2888 0.2874 0.2856 0.2883 0.2825\n",
      " 0.282 ]\n",
      "step: 70 \ttraining acc: [0.1825     0.38       0.40375    0.41208333 0.40791667 0.41416667]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05875]\n",
      "step: 80 \ttraining acc: [0.21916667 0.3975     0.43       0.43958333 0.44541667 0.44541667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07208333]\n",
      "step: 90 \ttraining acc: [0.18291667 0.39083333 0.4175     0.43       0.43875    0.44      ]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.09125]\n",
      "step: 100 \ttraining acc: [0.19583333 0.42416667 0.4475     0.45583333 0.45291667 0.45458333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07041667]\n",
      "step: 110 \ttraining acc: [0.21166667 0.39291667 0.43208333 0.44125    0.44208333 0.44166667]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07375]\n",
      "step: 120 \ttraining acc: [0.21083333 0.38041667 0.41875    0.42625    0.4325     0.43375   ]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06375]\n",
      "Test acc: [0.2007 0.3267 0.3462 0.352  0.3552 0.3552 0.3564 0.356  0.356  0.356\n",
      " 0.356 ]\n",
      "Test acc_adv: [0.03333 0.0952  0.0995  0.09827 0.09467 0.0936  0.0924  0.09094 0.0888\n",
      " 0.0889  0.08813]\n",
      "Test acc_adv_prior: [0.1576 0.2825 0.281  0.272  0.259  0.2554 0.251  0.2473 0.242  0.2423\n",
      " 0.2399]\n",
      "step: 0 \ttraining acc: [0.2225     0.4025     0.43125    0.4375     0.44208333 0.44583333]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0725]\n",
      "Test acc: [0.2001 0.316  0.3462 0.3547 0.3594 0.3625 0.364  0.3635 0.3645 0.3635\n",
      " 0.3645]\n",
      "Test acc_adv: [0.03574 0.1     0.10376 0.104   0.1005  0.0988  0.0987  0.0976  0.0977\n",
      " 0.0968  0.0961 ]\n",
      "Test acc_adv_prior: [0.1736 0.3113 0.292  0.2888 0.2744 0.2656 0.2654 0.2617 0.2605 0.2598\n",
      " 0.257 ]\n",
      "step: 10 \ttraining acc: [0.21333333 0.40583333 0.44166667 0.44791667 0.45208333 0.45166667]\n",
      "step: 10 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.08]\n",
      "step: 20 \ttraining acc: [0.17666667 0.39583333 0.4375     0.44708333 0.45541667 0.46      ]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "step: 30 \ttraining acc: [0.1675     0.415      0.44791667 0.45041667 0.4525     0.45541667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07708333]\n",
      "step: 40 \ttraining acc: [0.22125    0.42083333 0.44583333 0.45125    0.45708333 0.45333333]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05875]\n",
      "step: 50 \ttraining acc: [0.18333333 0.40791667 0.4475     0.46041667 0.46375    0.46791667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08166667]\n",
      "step: 60 \ttraining acc: [0.2075     0.41333333 0.4725     0.47291667 0.47208333 0.47125   ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06083333]\n",
      "Test acc: [0.2106 0.3403 0.36   0.3674 0.3674 0.3696 0.369  0.3677 0.3667 0.3652\n",
      " 0.365 ]\n",
      "Test acc_adv: [0.0452  0.1111  0.1132  0.1101  0.1119  0.1096  0.10785 0.1077  0.1064\n",
      " 0.10614 0.1048 ]\n",
      "Test acc_adv_prior: [0.2069 0.3186 0.3044 0.2915 0.2954 0.287  0.2842 0.2842 0.2832 0.282\n",
      " 0.2786]\n",
      "step: 70 \ttraining acc: [0.21791667 0.40458333 0.43875    0.44625    0.45375    0.45708333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06166667]\n",
      "step: 80 \ttraining acc: [0.18541667 0.43166667 0.455      0.46416667 0.46625    0.46833333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07833333]\n",
      "step: 90 \ttraining acc: [0.21208333 0.43166667 0.45916667 0.46333333 0.46125    0.465     ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06666667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100 \ttraining acc: [0.22625    0.45333333 0.47666667 0.48041667 0.48083333 0.4825    ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06791667]\n",
      "step: 110 \ttraining acc: [0.19583333 0.43666667 0.46       0.47333333 0.47125    0.4775    ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06583333]\n",
      "step: 120 \ttraining acc: [0.1975     0.42583333 0.45541667 0.46833333 0.46958333 0.47083333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06708333]\n",
      "Test acc: [0.1885 0.3318 0.3599 0.3672 0.372  0.3735 0.3733 0.3738 0.3716 0.3716\n",
      " 0.372 ]\n",
      "Test acc_adv: [0.034   0.0903  0.1032  0.1008  0.09906 0.09656 0.0952  0.0932  0.09265\n",
      " 0.0924  0.092  ]\n",
      "Test acc_adv_prior: [0.1692 0.2607 0.2766 0.2673 0.2576 0.2505 0.2468 0.2416 0.2412 0.2393\n",
      " 0.2389]\n",
      "step: 0 \ttraining acc: [0.19083333 0.40458333 0.43291667 0.44291667 0.445      0.44708333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05708333]\n",
      "Test acc: [0.1849 0.319  0.3518 0.359  0.3606 0.3596 0.3596 0.3584 0.3596 0.3606\n",
      " 0.3606]\n",
      "Test acc_adv: [0.0332  0.09534 0.1003  0.0961  0.0923  0.0888  0.0844  0.0835  0.0824\n",
      " 0.08307 0.0817 ]\n",
      "Test acc_adv_prior: [0.1709 0.2903 0.274  0.2568 0.245  0.2369 0.2245 0.2233 0.2188 0.2203\n",
      " 0.2162]\n",
      "step: 10 \ttraining acc: [0.18708333 0.4025     0.42791667 0.43375    0.43291667 0.43541667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07208333]\n",
      "step: 20 \ttraining acc: [0.21291667 0.4375     0.46041667 0.46541667 0.46541667 0.46666667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05291667]\n",
      "step: 30 \ttraining acc: [0.20291667 0.39958333 0.41958333 0.42416667 0.42583333 0.4275    ]\n",
      "step: 30 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0675]\n",
      "step: 40 \ttraining acc: [0.19833333 0.42625    0.45125    0.45708333 0.45791667 0.45708333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06083333]\n",
      "step: 50 \ttraining acc: [0.20291667 0.40208333 0.42916667 0.44083333 0.44416667 0.4475    ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06041667]\n",
      "step: 60 \ttraining acc: [0.20916667 0.41       0.44041667 0.44791667 0.44625    0.4475    ]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "Test acc: [0.1917 0.322  0.353  0.3586 0.3582 0.3599 0.3616 0.3608 0.361  0.361\n",
      " 0.362 ]\n",
      "Test acc_adv: [0.0424  0.09296 0.10016 0.10016 0.09906 0.0993  0.09827 0.0967  0.0959\n",
      " 0.09656 0.0956 ]\n",
      "Test acc_adv_prior: [0.2076 0.2812 0.2756 0.2715 0.268  0.2678 0.265  0.2605 0.259  0.2603\n",
      " 0.2583]\n",
      "step: 70 \ttraining acc: [0.21416667 0.4075     0.42375    0.42833333 0.43916667 0.4425    ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06041667]\n",
      "step: 80 \ttraining acc: [0.20125    0.37541667 0.41583333 0.42375    0.42875    0.43041667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05583333]\n",
      "step: 90 \ttraining acc: [0.195      0.4        0.42       0.42833333 0.43208333 0.43458333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05583333]\n",
      "step: 100 \ttraining acc: [0.21541667 0.43541667 0.46583333 0.46958333 0.47208333 0.46916667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05541667]\n",
      "step: 110 \ttraining acc: [0.21333333 0.48666667 0.5        0.50958333 0.50958333 0.51416667]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0825]\n",
      "step: 120 \ttraining acc: [0.21       0.43291667 0.45125    0.45916667 0.46125    0.46      ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06208333]\n",
      "Test acc: [0.2039 0.3462 0.3574 0.363  0.364  0.3665 0.3645 0.3635 0.3638 0.365\n",
      " 0.3652]\n",
      "Test acc_adv: [0.04266 0.1039  0.1013  0.0992  0.09656 0.0951  0.09265 0.09064 0.0916\n",
      " 0.09106 0.0895 ]\n",
      "Test acc_adv_prior: [0.2024 0.2876 0.2754 0.267  0.259  0.2544 0.2498 0.244  0.247  0.2448\n",
      " 0.2404]\n",
      "step: 0 \ttraining acc: [0.20458333 0.415      0.4425     0.4425     0.44166667 0.44083333]\n",
      "step: 0 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.055]\n",
      "Test acc: [0.212  0.3416 0.3604 0.3613 0.365  0.3657 0.3652 0.3655 0.3647 0.3647\n",
      " 0.365 ]\n",
      "Test acc_adv: [0.03586 0.09424 0.1016  0.09894 0.0952  0.0939  0.0944  0.0915  0.0896\n",
      " 0.0897  0.08856]\n",
      "Test acc_adv_prior: [0.1643 0.2642 0.2737 0.2666 0.2522 0.2482 0.2502 0.243  0.2384 0.2383\n",
      " 0.2354]\n",
      "step: 10 \ttraining acc: [0.19666667 0.41       0.43125    0.4325     0.44       0.43958333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06583333]\n",
      "step: 20 \ttraining acc: [0.20666667 0.42041667 0.4325     0.44       0.44083333 0.44291667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06208333]\n",
      "step: 30 \ttraining acc: [0.1975     0.41875    0.45416667 0.45708333 0.465      0.46375   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05666667]\n",
      "step: 40 \ttraining acc: [0.22125    0.43875    0.46041667 0.46875    0.46833333 0.46791667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07833333]\n",
      "step: 50 \ttraining acc: [0.2025     0.43333333 0.44916667 0.45583333 0.455      0.45791667]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05625]\n",
      "step: 60 \ttraining acc: [0.20291667 0.4175     0.43041667 0.43958333 0.44208333 0.43916667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05291667]\n",
      "Test acc: [0.1937 0.3323 0.358  0.3594 0.363  0.3638 0.363  0.3623 0.3623 0.3633\n",
      " 0.363 ]\n",
      "Test acc_adv: [0.03253 0.09    0.09265 0.0932  0.0932  0.09296 0.0908  0.0892  0.09015\n",
      " 0.0879  0.0892 ]\n",
      "Test acc_adv_prior: [0.1573 0.2625 0.252  0.2524 0.2495 0.2472 0.2427 0.2384 0.2405 0.2334\n",
      " 0.2383]\n",
      "step: 70 \ttraining acc: [0.23208333 0.43166667 0.44458333 0.4475     0.44833333 0.44833333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "step: 80 \ttraining acc: [0.19125    0.42791667 0.45708333 0.46041667 0.46083333 0.46083333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06875]\n",
      "step: 90 \ttraining acc: [0.1875     0.48958333 0.50541667 0.51541667 0.51875    0.51875   ]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07125]\n",
      "step: 100 \ttraining acc: [0.17958333 0.37625    0.39583333 0.39708333 0.4025     0.40166667]\n",
      "step: 100 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.05]\n",
      "step: 110 \ttraining acc: [0.18208333 0.42791667 0.45166667 0.46       0.46291667 0.46375   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06208333]\n",
      "step: 120 \ttraining acc: [0.20958333 0.42708333 0.44541667 0.45333333 0.45583333 0.45541667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07833333]\n",
      "Test acc: [0.2012 0.3372 0.3591 0.3616 0.3655 0.3647 0.367  0.368  0.367  0.3657\n",
      " 0.366 ]\n",
      "Test acc_adv: [0.02814 0.09174 0.0972  0.0949  0.0932  0.09106 0.08984 0.0896  0.08905\n",
      " 0.0887  0.08826]\n",
      "Test acc_adv_prior: [0.131  0.267  0.2642 0.2559 0.249  0.243  0.2393 0.2375 0.2367 0.2367\n",
      " 0.2351]\n",
      "step: 0 \ttraining acc: [0.21375    0.47125    0.47666667 0.48       0.48041667 0.48041667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06791667]\n",
      "Test acc: [0.1963 0.348  0.3667 0.3655 0.3674 0.368  0.3682 0.3691 0.3691 0.3684\n",
      " 0.3682]\n",
      "Test acc_adv: [0.02786 0.1116  0.1077  0.10547 0.1028  0.1     0.1     0.09814 0.0969\n",
      " 0.09705 0.0949 ]\n",
      "Test acc_adv_prior: [0.134  0.306  0.2817 0.276  0.2693 0.2612 0.262  0.2578 0.2542 0.2544\n",
      " 0.2498]\n",
      "step: 10 \ttraining acc: [0.19333333 0.42208333 0.455      0.46791667 0.46791667 0.46916667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04916667]\n",
      "step: 20 \ttraining acc: [0.20208333 0.41       0.43583333 0.44625    0.44916667 0.45      ]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "step: 30 \ttraining acc: [0.1975     0.40708333 0.43416667 0.43833333 0.43916667 0.44125   ]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 40 \ttraining acc: [0.20333333 0.42625    0.44666667 0.45041667 0.45333333 0.45208333]\n",
      "step: 40 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.065]\n",
      "step: 50 \ttraining acc: [0.15833333 0.435      0.465      0.47083333 0.47416667 0.47708333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06833333]\n",
      "step: 60 \ttraining acc: [0.18666667 0.43208333 0.45208333 0.45333333 0.45666667 0.4625    ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05583333]\n",
      "Test acc: [0.1923 0.3523 0.3733 0.3745 0.3777 0.3777 0.3774 0.3767 0.3762 0.3757\n",
      " 0.3755]\n",
      "Test acc_adv: [0.03494 0.102   0.1008  0.0992  0.09814 0.0961  0.094   0.0913  0.0908\n",
      " 0.09015 0.09   ]\n",
      "Test acc_adv_prior: [0.175  0.2795 0.2634 0.2573 0.2524 0.2476 0.2416 0.2356 0.2345 0.2341\n",
      " 0.2327]\n",
      "step: 70 \ttraining acc: [0.19875    0.4025     0.42875    0.43791667 0.43833333 0.43791667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04833333]\n",
      "step: 80 \ttraining acc: [0.19041667 0.39708333 0.43541667 0.44541667 0.45125    0.45583333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04375]\n",
      "step: 90 \ttraining acc: [0.2025     0.40958333 0.44833333 0.45041667 0.45375    0.45416667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07541667]\n",
      "step: 100 \ttraining acc: [0.19291667 0.40958333 0.44208333 0.4525     0.45416667 0.45541667]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05125]\n",
      "step: 110 \ttraining acc: [0.19666667 0.43875    0.45541667 0.46       0.46333333 0.465     ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06416667]\n",
      "step: 120 \ttraining acc: [0.21625    0.4325     0.45333333 0.46       0.46166667 0.46166667]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05375]\n",
      "Test acc: [0.1925 0.332  0.3616 0.3645 0.362  0.361  0.3618 0.3633 0.3623 0.3616\n",
      " 0.3618]\n",
      "Test acc_adv: [0.04108 0.1059  0.09894 0.0923  0.08734 0.0843  0.08136 0.07904 0.07947\n",
      " 0.0764  0.0752 ]\n",
      "Test acc_adv_prior: [0.2037 0.3135 0.2668 0.2483 0.2349 0.2269 0.2184 0.2126 0.2141 0.2064\n",
      " 0.2029]\n",
      "step: 0 \ttraining acc: [0.19625    0.42958333 0.45458333 0.46       0.45666667 0.45166667]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "Test acc: [0.1895 0.353  0.3606 0.3647 0.3618 0.3645 0.363  0.364  0.366  0.366\n",
      " 0.3665]\n",
      "Test acc_adv: [0.02013 0.0912  0.08746 0.0864  0.08295 0.08014 0.0779  0.0781  0.0763\n",
      " 0.0753  0.0753 ]\n",
      "Test acc_adv_prior: [0.1053 0.2524 0.2367 0.2322 0.2257 0.2174 0.212  0.211  0.206  0.2043\n",
      " 0.2046]\n",
      "step: 10 \ttraining acc: [0.15833333 0.44041667 0.46083333 0.46166667 0.46916667 0.47125   ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06041667]\n",
      "step: 20 \ttraining acc: [0.20583333 0.46708333 0.48458333 0.49166667 0.49208333 0.49125   ]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0525]\n",
      "step: 30 \ttraining acc: [0.1925     0.39708333 0.42041667 0.425      0.4275     0.4275    ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05208333]\n",
      "step: 40 \ttraining acc: [0.22291667 0.42583333 0.44458333 0.44875    0.44791667 0.44875   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05291667]\n",
      "step: 50 \ttraining acc: [0.1925     0.44916667 0.47083333 0.47666667 0.47208333 0.47125   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05208333]\n",
      "step: 60 \ttraining acc: [0.20833333 0.4325     0.44833333 0.45166667 0.45583333 0.45416667]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0525]\n",
      "Test acc: [0.2042 0.3484 0.3667 0.3708 0.374  0.3743 0.372  0.3735 0.3723 0.3716\n",
      " 0.3718]\n",
      "Test acc_adv: [0.02853 0.0913  0.09094 0.0897  0.0876  0.08545 0.0833  0.0828  0.08215\n",
      " 0.08295 0.0804 ]\n",
      "Test acc_adv_prior: [0.1387 0.2563 0.2427 0.2367 0.2285 0.2229 0.2191 0.2167 0.2162 0.2172\n",
      " 0.2108]\n",
      "step: 70 \ttraining acc: [0.2025     0.43708333 0.45916667 0.47291667 0.47291667 0.47333333]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06375]\n",
      "step: 80 \ttraining acc: [0.20375    0.43625    0.45       0.45166667 0.45375    0.45583333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04333333]\n",
      "step: 90 \ttraining acc: [0.17125    0.40291667 0.43833333 0.43958333 0.44125    0.44125   ]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0425]\n",
      "step: 100 \ttraining acc: [0.1925     0.4375     0.46541667 0.47375    0.475      0.47916667]\n",
      "step: 100 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.05]\n",
      "step: 110 \ttraining acc: [0.19416667 0.46083333 0.4875     0.49541667 0.49833333 0.50083333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05958333]\n",
      "step: 120 \ttraining acc: [0.1875     0.44708333 0.45833333 0.46333333 0.46708333 0.47166667]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05125]\n",
      "Test acc: [0.2124 0.3513 0.3723 0.3706 0.3694 0.368  0.3657 0.3655 0.3645 0.3638\n",
      " 0.3635]\n",
      "Test acc_adv: [0.042   0.1163  0.1092  0.1016  0.0941  0.0897  0.0868  0.08185 0.0817\n",
      " 0.0807  0.07947]\n",
      "Test acc_adv_prior: [0.1843 0.3286 0.2874 0.268  0.2498 0.239  0.2327 0.2178 0.218  0.2151\n",
      " 0.2119]\n",
      "step: 0 \ttraining acc: [0.18833333 0.45208333 0.47583333 0.48583333 0.48708333 0.48541667]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07125]\n",
      "Test acc: [0.1956 0.3364 0.3562 0.3638 0.3672 0.3647 0.3647 0.3645 0.366  0.3662\n",
      " 0.366 ]\n",
      "Test acc_adv: [0.0324  0.09265 0.0972  0.092   0.0884  0.08624 0.08575 0.0852  0.08496\n",
      " 0.0843  0.0833 ]\n",
      "Test acc_adv_prior: [0.1649 0.2666 0.266  0.2456 0.2355 0.2319 0.2296 0.2283 0.2268 0.2246\n",
      " 0.222 ]\n",
      "step: 10 \ttraining acc: [0.23041667 0.44       0.47083333 0.4775     0.48333333 0.48333333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04208333]\n",
      "step: 20 \ttraining acc: [0.20958333 0.50833333 0.52833333 0.53041667 0.52875    0.52625   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06916667]\n",
      "step: 30 \ttraining acc: [0.21625    0.425      0.44166667 0.44791667 0.45041667 0.45083333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04958333]\n",
      "step: 40 \ttraining acc: [0.185      0.4475     0.46625    0.4725     0.47583333 0.48125   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04916667]\n",
      "step: 50 \ttraining acc: [0.17583333 0.39875    0.4275     0.4375     0.44666667 0.44708333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03916667]\n",
      "step: 60 \ttraining acc: [0.235      0.44416667 0.46       0.46583333 0.46625    0.46458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05083333]\n",
      "Test acc: [0.2051 0.3445 0.3662 0.369  0.3704 0.37   0.3704 0.3704 0.37   0.3696\n",
      " 0.3691]\n",
      "Test acc_adv: [0.01947 0.0817  0.0796  0.0769  0.07654 0.07465 0.0743  0.072   0.0716\n",
      " 0.0724  0.0699 ]\n",
      "Test acc_adv_prior: [0.09564 0.2267  0.2087  0.1997  0.1985  0.1946  0.1932  0.1862  0.1854\n",
      " 0.1876  0.1821 ]\n",
      "step: 70 \ttraining acc: [0.19708333 0.405      0.43291667 0.44375    0.45166667 0.45333333]\n",
      "step: 70 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.05]\n",
      "step: 80 \ttraining acc: [0.20541667 0.40666667 0.42416667 0.42916667 0.43125    0.42958333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02958333]\n",
      "step: 90 \ttraining acc: [0.19541667 0.43125    0.44791667 0.45208333 0.45125    0.45208333]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05375]\n",
      "step: 100 \ttraining acc: [0.2025     0.44958333 0.46791667 0.47375    0.46666667 0.46791667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04666667]\n",
      "step: 110 \ttraining acc: [0.23041667 0.43791667 0.46083333 0.46375    0.46583333 0.46625   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05458333]\n",
      "step: 120 \ttraining acc: [0.20125    0.39958333 0.42041667 0.42458333 0.42166667 0.4225    ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: [0.201  0.3455 0.3582 0.3591 0.3586 0.3582 0.359  0.3606 0.3604 0.3608\n",
      " 0.361 ]\n",
      "Test acc_adv: [0.0312  0.0848  0.07825 0.07733 0.07587 0.0728  0.07104 0.06976 0.0699\n",
      " 0.06824 0.06775]\n",
      "Test acc_adv_prior: [0.1514 0.2338 0.2062 0.2047 0.2023 0.1941 0.1884 0.1841 0.1844 0.1787\n",
      " 0.1775]\n",
      "step: 0 \ttraining acc: [0.18666667 0.43125    0.46416667 0.47041667 0.47625    0.47708333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04166667]\n",
      "Test acc: [0.2042 0.3376 0.3687 0.3718 0.3743 0.3738 0.372  0.3726 0.3723 0.3713\n",
      " 0.3708]\n",
      "Test acc_adv: [0.04266 0.08655 0.08374 0.0804  0.0776  0.0751  0.0748  0.07294 0.07227\n",
      " 0.07184 0.06934]\n",
      "Test acc_adv_prior: [0.1866 0.252  0.2212 0.212  0.2017 0.1971 0.1968 0.1909 0.1901 0.1902\n",
      " 0.1831]\n",
      "step: 10 \ttraining acc: [0.22916667 0.41958333 0.44375    0.44666667 0.44625    0.45      ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03916667]\n",
      "step: 20 \ttraining acc: [0.18916667 0.43666667 0.455      0.46083333 0.46583333 0.46416667]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04375]\n",
      "step: 30 \ttraining acc: [0.2175     0.44458333 0.46458333 0.47041667 0.46958333 0.47125   ]\n",
      "step: 30 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0575]\n",
      "step: 40 \ttraining acc: [0.20375    0.445      0.46791667 0.47083333 0.47375    0.47375   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05708333]\n",
      "step: 50 \ttraining acc: [0.19791667 0.42958333 0.45166667 0.45958333 0.46166667 0.46125   ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03875]\n",
      "step: 60 \ttraining acc: [0.20208333 0.4775     0.50166667 0.50541667 0.50791667 0.50625   ]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.07375]\n",
      "Test acc: [0.1925 0.3428 0.3564 0.361  0.3643 0.3662 0.3647 0.3662 0.3672 0.3672\n",
      " 0.3674]\n",
      "Test acc_adv: [0.02774 0.08545 0.08136 0.08014 0.07544 0.0736  0.07214 0.0727  0.0715\n",
      " 0.0715  0.0689 ]\n",
      "Test acc_adv_prior: [0.1365 0.2408 0.2213 0.215  0.2002 0.1932 0.1907 0.191  0.1877 0.1873\n",
      " 0.1813]\n",
      "step: 70 \ttraining acc: [0.20791667 0.44333333 0.46791667 0.47083333 0.46791667 0.47083333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04583333]\n",
      "step: 80 \ttraining acc: [0.18791667 0.42125    0.44666667 0.45291667 0.46083333 0.46125   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "step: 90 \ttraining acc: [0.22041667 0.48708333 0.50583333 0.50916667 0.51       0.51166667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04583333]\n",
      "step: 100 \ttraining acc: [0.19833333 0.44166667 0.46291667 0.46041667 0.45916667 0.46166667]\n",
      "step: 100 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.045]\n",
      "step: 110 \ttraining acc: [0.20958333 0.42291667 0.45041667 0.45458333 0.4525     0.45291667]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04375]\n",
      "step: 120 \ttraining acc: [0.2        0.44791667 0.455      0.45625    0.45833333 0.46083333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05208333]\n",
      "Test acc: [0.1985 0.3538 0.365  0.3665 0.368  0.3687 0.3699 0.3696 0.3699 0.3704\n",
      " 0.3706]\n",
      "Test acc_adv: [0.02133 0.0843  0.0835  0.07855 0.07544 0.0743  0.0712  0.0715  0.07\n",
      " 0.0692  0.0684 ]\n",
      "Test acc_adv_prior: [0.10645 0.2286  0.2208  0.2059  0.1986  0.1954  0.187   0.1877  0.1832\n",
      " 0.1814  0.1788 ]\n",
      "step: 0 \ttraining acc: [0.18916667 0.43458333 0.46041667 0.46541667 0.4625     0.46166667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04833333]\n",
      "Test acc: [0.2052 0.3604 0.376  0.377  0.3777 0.377  0.3772 0.3774 0.3767 0.3757\n",
      " 0.3767]\n",
      "Test acc_adv: [0.022   0.0859  0.08905 0.0851  0.08386 0.0832  0.08014 0.0792  0.07825\n",
      " 0.07745 0.0779 ]\n",
      "Test acc_adv_prior: [0.1003 0.2318 0.2285 0.2164 0.2124 0.21   0.2017 0.1998 0.1984 0.1973\n",
      " 0.1979]\n",
      "step: 10 \ttraining acc: [0.19083333 0.42208333 0.44       0.44541667 0.44791667 0.44875   ]\n",
      "step: 10 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.05]\n",
      "step: 20 \ttraining acc: [0.20541667 0.46708333 0.48541667 0.49125    0.49041667 0.49      ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04791667]\n",
      "step: 30 \ttraining acc: [0.20416667 0.47125    0.47833333 0.48333333 0.48041667 0.4825    ]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05875]\n",
      "step: 40 \ttraining acc: [0.20958333 0.45166667 0.46625    0.47666667 0.47708333 0.47708333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "step: 50 \ttraining acc: [0.21375    0.45666667 0.48916667 0.49208333 0.49125    0.49375   ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06375]\n",
      "step: 60 \ttraining acc: [0.1625     0.47875    0.50041667 0.51291667 0.51625    0.51583333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04791667]\n",
      "Test acc: [0.2094 0.3542 0.3748 0.3765 0.3767 0.3752 0.3748 0.3733 0.373  0.373\n",
      " 0.3738]\n",
      "Test acc_adv: [0.03815 0.0908  0.08374 0.0796  0.07733 0.0725  0.07227 0.07056 0.06976\n",
      " 0.06934 0.06934]\n",
      "Test acc_adv_prior: [0.1759 0.2524 0.2161 0.2037 0.198  0.1875 0.1866 0.1833 0.1809 0.1808\n",
      " 0.1805]\n",
      "step: 70 \ttraining acc: [0.17333333 0.4125     0.44458333 0.45375    0.45166667 0.45208333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03833333]\n",
      "step: 80 \ttraining acc: [0.19833333 0.39916667 0.43208333 0.43708333 0.44125    0.44125   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n",
      "step: 90 \ttraining acc: [0.16458333 0.41125    0.45125    0.455      0.45708333 0.45333333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04666667]\n",
      "step: 100 \ttraining acc: [0.1975     0.42375    0.44458333 0.45208333 0.45333333 0.4575    ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04708333]\n",
      "step: 110 \ttraining acc: [0.19416667 0.44       0.45791667 0.46541667 0.46708333 0.47083333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03958333]\n",
      "step: 120 \ttraining acc: [0.18375    0.45375    0.47708333 0.48291667 0.485      0.48583333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04958333]\n",
      "Test acc: [0.2053 0.3545 0.378  0.377  0.3767 0.377  0.3765 0.3755 0.3752 0.3755\n",
      " 0.3752]\n",
      "Test acc_adv: [0.0304  0.0887  0.08215 0.0796  0.0769  0.0748  0.0732  0.07184 0.0717\n",
      " 0.0717  0.0709 ]\n",
      "Test acc_adv_prior: [0.1498 0.2439 0.2104 0.2037 0.1979 0.1929 0.1876 0.185  0.1854 0.1849\n",
      " 0.1837]\n",
      "step: 0 \ttraining acc: [0.2        0.44916667 0.48083333 0.48583333 0.49041667 0.49083333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04958333]\n",
      "Test acc: [0.1927 0.3535 0.3728 0.3718 0.3743 0.3752 0.3752 0.3752 0.3762 0.3748\n",
      " 0.3745]\n",
      "Test acc_adv: [0.02293 0.0925  0.0868  0.0828  0.07904 0.0763  0.07465 0.074   0.0727\n",
      " 0.0716  0.07135]\n",
      "Test acc_adv_prior: [0.1137 0.2537 0.2242 0.2135 0.2032 0.196  0.1912 0.1906 0.1849 0.1832\n",
      " 0.1846]\n",
      "step: 10 \ttraining acc: [0.2025     0.44708333 0.46791667 0.47166667 0.47375    0.47083333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05458333]\n",
      "step: 20 \ttraining acc: [0.19375    0.42041667 0.43791667 0.4425     0.43958333 0.44166667]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0425]\n",
      "step: 30 \ttraining acc: [0.20125    0.46416667 0.49208333 0.49708333 0.49666667 0.49791667]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.06875]\n",
      "step: 40 \ttraining acc: [0.19791667 0.4675     0.49458333 0.49916667 0.50458333 0.50333333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04666667]\n",
      "step: 50 \ttraining acc: [0.20958333 0.44333333 0.45291667 0.45291667 0.45833333 0.45708333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04041667]\n",
      "step: 60 \ttraining acc: [0.19458333 0.41916667 0.43458333 0.43208333 0.43458333 0.43375   ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: [0.2009 0.3665 0.376  0.3774 0.3755 0.3748 0.3772 0.3762 0.376  0.376\n",
      " 0.375 ]\n",
      "Test acc_adv: [0.0212  0.08936 0.0856  0.0808  0.0761  0.07227 0.0708  0.0708  0.07\n",
      " 0.06866 0.068  ]\n",
      "Test acc_adv_prior: [0.0982 0.2267 0.217  0.2052 0.1935 0.185  0.1798 0.1809 0.1792 0.1752\n",
      " 0.1738]\n",
      "step: 70 \ttraining acc: [0.19791667 0.42458333 0.44208333 0.44708333 0.44958333 0.44958333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04083333]\n",
      "step: 80 \ttraining acc: [0.19375    0.44583333 0.46708333 0.47458333 0.48       0.48125   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04291667]\n",
      "step: 90 \ttraining acc: [0.19833333 0.47958333 0.49625    0.4975     0.49583333 0.49583333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06541667]\n",
      "step: 100 \ttraining acc: [0.21208333 0.45875    0.475      0.4775     0.48166667 0.48083333]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03625]\n",
      "step: 110 \ttraining acc: [0.19083333 0.46       0.47208333 0.47458333 0.47791667 0.47666667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06458333]\n",
      "step: 120 \ttraining acc: [0.17291667 0.45916667 0.48083333 0.49041667 0.49458333 0.495     ]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05625]\n",
      "Test acc: [0.1985 0.3516 0.3762 0.38   0.3806 0.3804 0.3809 0.3813 0.3828 0.3818\n",
      " 0.3823]\n",
      "Test acc_adv: [0.03665 0.10535 0.09424 0.0864  0.0817  0.0796  0.07666 0.0751  0.0727\n",
      " 0.0727  0.07135]\n",
      "Test acc_adv_prior: [0.1696 0.2886 0.2399 0.2177 0.2064 0.1996 0.1917 0.1876 0.181  0.182\n",
      " 0.1777]\n",
      "step: 0 \ttraining acc: [0.21166667 0.42208333 0.4425     0.45041667 0.44875    0.45125   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03666667]\n",
      "Test acc: [0.2018 0.3542 0.368  0.3704 0.37   0.3706 0.3706 0.3694 0.3682 0.3677\n",
      " 0.3677]\n",
      "Test acc_adv: [0.0236  0.08    0.0796  0.07733 0.0743  0.072   0.0699  0.06946 0.06976\n",
      " 0.0676  0.06824]\n",
      "Test acc_adv_prior: [0.1072 0.2157 0.2054 0.1992 0.1904 0.1852 0.1796 0.1809 0.1816 0.1761\n",
      " 0.1772]\n",
      "step: 10 \ttraining acc: [0.1825     0.46125    0.47791667 0.49       0.49625    0.50416667]\n",
      "step: 10 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0675]\n",
      "step: 20 \ttraining acc: [0.19708333 0.44541667 0.45708333 0.46416667 0.46958333 0.47041667]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0325]\n",
      "step: 30 \ttraining acc: [0.2125     0.39416667 0.42541667 0.43875    0.43958333 0.44458333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03916667]\n",
      "step: 40 \ttraining acc: [0.21541667 0.46041667 0.48416667 0.48708333 0.48875    0.48791667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03708333]\n",
      "step: 50 \ttraining acc: [0.2075     0.47125    0.49291667 0.49916667 0.50041667 0.50416667]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04375]\n",
      "step: 60 \ttraining acc: [0.20583333 0.44       0.45583333 0.46208333 0.46416667 0.46458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04041667]\n",
      "Test acc: [0.1982 0.3508 0.3767 0.379  0.379  0.378  0.3765 0.3767 0.376  0.376\n",
      " 0.3767]\n",
      "Test acc_adv: [0.02826 0.09814 0.09094 0.08185 0.0764  0.07385 0.0707  0.0684  0.0679\n",
      " 0.0653  0.064  ]\n",
      "Test acc_adv_prior: [0.1357 0.2703 0.2329 0.2078 0.1943 0.189  0.1812 0.1744 0.1737 0.166\n",
      " 0.162 ]\n",
      "step: 70 \ttraining acc: [0.20208333 0.48125    0.49708333 0.49333333 0.495      0.49625   ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04166667]\n",
      "step: 80 \ttraining acc: [0.23208333 0.44416667 0.45708333 0.46       0.4625     0.46083333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03416667]\n",
      "step: 90 \ttraining acc: [0.18458333 0.46625    0.48333333 0.48208333 0.48833333 0.4875    ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04416667]\n",
      "step: 100 \ttraining acc: [0.17625    0.4675     0.47416667 0.47166667 0.4675     0.46791667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04541667]\n",
      "step: 110 \ttraining acc: [0.19958333 0.46333333 0.47083333 0.475      0.47541667 0.47708333]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04375]\n",
      "step: 120 \ttraining acc: [0.20958333 0.46791667 0.50416667 0.50833333 0.50833333 0.50958333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05416667]\n",
      "Test acc: [0.1975 0.3381 0.3625 0.3652 0.3657 0.367  0.3694 0.368  0.3677 0.3694\n",
      " 0.3691]\n",
      "Test acc_adv: [0.03308 0.092   0.0784  0.0743  0.0715  0.0696  0.06775 0.0673  0.0668\n",
      " 0.0664  0.0665 ]\n",
      "Test acc_adv_prior: [0.1444 0.2642 0.2074 0.196  0.1888 0.1838 0.1774 0.1766 0.1759 0.1742\n",
      " 0.1743]\n",
      "step: 0 \ttraining acc: [0.20166667 0.47458333 0.49875    0.50208333 0.50958333 0.50833333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05458333]\n",
      "Test acc: [0.1998 0.3472 0.3628 0.3657 0.367  0.3682 0.3687 0.3694 0.3696 0.3694\n",
      " 0.3694]\n",
      "Test acc_adv: [0.02667 0.0879  0.078   0.0727  0.0712  0.0668  0.0643  0.06384 0.0628\n",
      " 0.0627  0.0624 ]\n",
      "Test acc_adv_prior: [0.1282 0.2494 0.2114 0.1962 0.1913 0.1797 0.1724 0.1705 0.1674 0.168\n",
      " 0.166 ]\n",
      "step: 10 \ttraining acc: [0.215      0.4925     0.51       0.51       0.50791667 0.51041667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05541667]\n",
      "step: 20 \ttraining acc: [0.18666667 0.38208333 0.39916667 0.40958333 0.40958333 0.40833333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n",
      "step: 30 \ttraining acc: [0.19541667 0.45458333 0.475      0.47958333 0.48291667 0.48375   ]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03625]\n",
      "step: 40 \ttraining acc: [0.22291667 0.4725     0.49083333 0.48708333 0.48416667 0.48583333]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0475]\n",
      "step: 50 \ttraining acc: [0.19958333 0.43708333 0.45625    0.46125    0.46416667 0.46458333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03458333]\n",
      "step: 60 \ttraining acc: [0.21       0.51       0.53958333 0.54541667 0.54833333 0.55125   ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "Test acc: [0.2051 0.3616 0.3706 0.3716 0.3733 0.373  0.3726 0.3728 0.3723 0.3718\n",
      " 0.3716]\n",
      "Test acc_adv: [0.0244  0.08014 0.07184 0.0668  0.0636  0.06226 0.0628  0.06186 0.0608\n",
      " 0.06107 0.06107]\n",
      "Test acc_adv_prior: [0.1193 0.2147 0.186  0.171  0.1619 0.1584 0.1605 0.1576 0.1555 0.1562\n",
      " 0.1562]\n",
      "step: 70 \ttraining acc: [0.22875    0.46541667 0.48       0.48       0.48       0.47791667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04791667]\n",
      "step: 80 \ttraining acc: [0.20083333 0.48083333 0.505      0.50791667 0.51041667 0.51333333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04958333]\n",
      "step: 90 \ttraining acc: [0.18291667 0.45916667 0.465      0.47083333 0.47375    0.47458333]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04125]\n",
      "step: 100 \ttraining acc: [0.20916667 0.44958333 0.4575     0.45791667 0.46583333 0.46458333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03416667]\n",
      "step: 110 \ttraining acc: [0.21291667 0.48291667 0.49375    0.49708333 0.4975     0.49833333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05416667]\n",
      "step: 120 \ttraining acc: [0.20291667 0.42208333 0.44916667 0.45208333 0.4525     0.455     ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04166667]\n",
      "Test acc: [0.2029 0.3608 0.374  0.3735 0.3716 0.371  0.3706 0.3699 0.3696 0.3706\n",
      " 0.3699]\n",
      "Test acc_adv: [0.03732 0.08624 0.0764  0.0712  0.06854 0.0672  0.06384 0.0632  0.06055\n",
      " 0.06067 0.0608 ]\n",
      "Test acc_adv_prior: [0.1763 0.2322 0.1989 0.1847 0.1782 0.1754 0.1669 0.1653 0.1588 0.158\n",
      " 0.159 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.19791667 0.45416667 0.47541667 0.48541667 0.4825     0.48125   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03541667]\n",
      "Test acc: [0.2123 0.3577 0.378  0.38   0.3818 0.3813 0.3816 0.3804 0.3806 0.3806\n",
      " 0.379 ]\n",
      "Test acc_adv: [0.02867 0.0781  0.0727  0.0691  0.0672  0.06573 0.0652  0.06464 0.0627\n",
      " 0.0643  0.06256]\n",
      "Test acc_adv_prior: [0.1322 0.214  0.1875 0.1783 0.1709 0.1669 0.1661 0.1656 0.1603 0.164\n",
      " 0.16  ]\n",
      "step: 10 \ttraining acc: [0.1925     0.47125    0.49333333 0.49208333 0.495      0.49458333]\n",
      "step: 10 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.05]\n",
      "step: 20 \ttraining acc: [0.19708333 0.46125    0.47958333 0.48083333 0.485      0.49      ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05833333]\n",
      "step: 30 \ttraining acc: [0.19541667 0.45625    0.46666667 0.47333333 0.47458333 0.47875   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04041667]\n",
      "step: 40 \ttraining acc: [0.1775     0.45       0.47208333 0.47083333 0.46958333 0.47166667]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03125]\n",
      "step: 50 \ttraining acc: [0.19375    0.46333333 0.48291667 0.48416667 0.4875     0.48541667]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04875]\n",
      "step: 60 \ttraining acc: [0.1775     0.41791667 0.4375     0.44208333 0.44166667 0.445     ]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.01875]\n",
      "Test acc: [0.1968 0.359  0.3804 0.386  0.3838 0.3843 0.3845 0.3838 0.3845 0.3853\n",
      " 0.3853]\n",
      "Test acc_adv: [0.03293 0.0853  0.078   0.0737  0.0692  0.0664  0.0644  0.0624  0.06186\n",
      " 0.0629  0.0588 ]\n",
      "Test acc_adv_prior: [0.1582 0.2275 0.1957 0.183  0.1732 0.1653 0.1608 0.1564 0.1554 0.158\n",
      " 0.148 ]\n",
      "step: 70 \ttraining acc: [0.16708333 0.42166667 0.44083333 0.44291667 0.44375    0.445     ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03875]\n",
      "step: 80 \ttraining acc: [0.21083333 0.42625    0.44416667 0.45666667 0.46125    0.46291667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03708333]\n",
      "step: 90 \ttraining acc: [0.19666667 0.43375    0.45333333 0.45708333 0.46125    0.46291667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04416667]\n",
      "step: 100 \ttraining acc: [0.19625    0.47041667 0.49541667 0.49958333 0.50416667 0.50375   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03958333]\n",
      "step: 110 \ttraining acc: [0.19291667 0.45583333 0.4775     0.47708333 0.4775     0.47916667]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03875]\n",
      "step: 120 \ttraining acc: [0.19833333 0.45375    0.465      0.465      0.46416667 0.46708333]\n",
      "step: 120 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0375]\n",
      "Test acc: [0.2006 0.362  0.375  0.3806 0.3809 0.379  0.3782 0.3774 0.3765 0.377\n",
      " 0.377 ]\n",
      "Test acc_adv: [0.02693 0.08215 0.07056 0.06573 0.06494 0.06305 0.06335 0.06174 0.06213\n",
      " 0.06186 0.06134]\n",
      "Test acc_adv_prior: [0.1285 0.2172 0.1825 0.1683 0.166  0.1605 0.1617 0.1582 0.16   0.1587\n",
      " 0.1566]\n",
      "step: 0 \ttraining acc: [0.18666667 0.48083333 0.51083333 0.52       0.52583333 0.52541667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05458333]\n",
      "Test acc: [0.1984 0.355  0.3733 0.3755 0.3752 0.3748 0.3735 0.3748 0.3748 0.3752\n",
      " 0.3757]\n",
      "Test acc_adv: [0.013336 0.0715   0.0652   0.062    0.05865  0.0576   0.0576   0.05573\n",
      " 0.0568   0.056    0.05573 ]\n",
      "Test acc_adv_prior: [0.0616 0.1948 0.171  0.1594 0.1519 0.1498 0.1487 0.1442 0.1466 0.145\n",
      " 0.1434]\n",
      "step: 10 \ttraining acc: [0.18416667 0.4575     0.47083333 0.47666667 0.48041667 0.48083333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04541667]\n",
      "step: 20 \ttraining acc: [0.19125    0.475      0.49       0.5025     0.5025     0.50541667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04083333]\n",
      "step: 30 \ttraining acc: [0.18958333 0.41208333 0.41958333 0.43125    0.42541667 0.42625   ]\n",
      "step: 30 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.035]\n",
      "step: 40 \ttraining acc: [0.21083333 0.46208333 0.46583333 0.47291667 0.47333333 0.47375   ]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0475]\n",
      "step: 50 \ttraining acc: [0.16958333 0.45166667 0.48708333 0.48958333 0.49083333 0.49333333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03666667]\n",
      "step: 60 \ttraining acc: [0.18916667 0.43375    0.45208333 0.4475     0.44833333 0.45166667]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0375]\n",
      "Test acc: [0.2034 0.36   0.3745 0.3752 0.3728 0.3748 0.3765 0.3762 0.375  0.3745\n",
      " 0.3735]\n",
      "Test acc_adv: [0.02066 0.0877  0.0756  0.07    0.0652  0.0628  0.06    0.0596  0.05814\n",
      " 0.0588  0.05826]\n",
      "Test acc_adv_prior: [0.10065 0.2365  0.1986  0.1823  0.169   0.1636  0.1538  0.1537  0.1511\n",
      " 0.1539  0.1516 ]\n",
      "step: 70 \ttraining acc: [0.17291667 0.46041667 0.48458333 0.48666667 0.48958333 0.48916667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04666667]\n",
      "step: 80 \ttraining acc: [0.18125    0.50375    0.51833333 0.51833333 0.52208333 0.52583333]\n",
      "step: 80 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0375]\n",
      "step: 90 \ttraining acc: [0.21833333 0.50083333 0.50333333 0.50291667 0.50333333 0.50375   ]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04625]\n",
      "step: 100 \ttraining acc: [0.19625    0.43125    0.44458333 0.44958333 0.44875    0.45125   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02333333]\n",
      "step: 110 \ttraining acc: [0.20791667 0.47708333 0.4875     0.49041667 0.4925     0.4975    ]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0475]\n",
      "step: 120 \ttraining acc: [0.20375    0.43416667 0.45541667 0.45583333 0.46041667 0.45958333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04833333]\n",
      "Test acc: [0.2031 0.3652 0.376  0.3784 0.3784 0.3804 0.3804 0.3792 0.3784 0.3787\n",
      " 0.3784]\n",
      "Test acc_adv: [0.02    0.0797  0.07    0.0663  0.06305 0.062   0.062   0.06146 0.0604\n",
      " 0.05948 0.06067]\n",
      "Test acc_adv_prior: [0.0935 0.2089 0.1781 0.167  0.1594 0.1554 0.1565 0.1553 0.1522 0.1508\n",
      " 0.1533]\n",
      "step: 0 \ttraining acc: [0.23083333 0.46833333 0.4825     0.48833333 0.48666667 0.48583333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05541667]\n",
      "Test acc: [0.1968 0.3613 0.371  0.375  0.3765 0.3767 0.374  0.375  0.3755 0.3755\n",
      " 0.3745]\n",
      "Test acc_adv: [0.01773 0.0761  0.0689  0.06696 0.06415 0.0616  0.06094 0.06    0.05933\n",
      " 0.05814 0.058  ]\n",
      "Test acc_adv_prior: [0.0858 0.2031 0.1814 0.1731 0.165  0.1582 0.1581 0.1556 0.153  0.1499\n",
      " 0.1504]\n",
      "step: 10 \ttraining acc: [0.20791667 0.50125    0.52208333 0.52458333 0.52833333 0.5275    ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04208333]\n",
      "step: 20 \ttraining acc: [0.1925     0.45541667 0.46958333 0.47083333 0.47291667 0.47166667]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02875]\n",
      "step: 30 \ttraining acc: [0.20875    0.47416667 0.48583333 0.48875    0.49083333 0.49458333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "step: 40 \ttraining acc: [0.2025     0.475      0.485      0.49375    0.49166667 0.49166667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02666667]\n",
      "step: 50 \ttraining acc: [0.19458333 0.46583333 0.48083333 0.48791667 0.49       0.49208333]\n",
      "step: 50 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0325]\n",
      "step: 60 \ttraining acc: [0.215      0.44333333 0.45625    0.46       0.46125    0.45958333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03208333]\n",
      "Test acc: [0.1995 0.3555 0.3667 0.3699 0.3687 0.3691 0.3708 0.37   0.3716 0.3716\n",
      " 0.372 ]\n",
      "Test acc_adv: [0.014534 0.06384  0.05774  0.05588  0.0548   0.05307  0.0532   0.05334\n",
      " 0.0532   0.05252  0.0512  ]\n",
      "Test acc_adv_prior: [0.07   0.1697 0.1497 0.1442 0.1415 0.137  0.1364 0.1373 0.1364 0.1349\n",
      " 0.1316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 70 \ttraining acc: [0.18291667 0.47625    0.50041667 0.505      0.50666667 0.5075    ]\n",
      "step: 70 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.025]\n",
      "step: 80 \ttraining acc: [0.22875    0.51583333 0.53333333 0.54041667 0.54375    0.54333333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05875]\n",
      "step: 90 \ttraining acc: [0.21541667 0.47666667 0.50125    0.50375    0.50208333 0.5075    ]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0325]\n",
      "step: 100 \ttraining acc: [0.20958333 0.47583333 0.4925     0.49625    0.49708333 0.49958333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03583333]\n",
      "step: 110 \ttraining acc: [0.18916667 0.45791667 0.47083333 0.47125    0.46916667 0.47      ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "step: 120 \ttraining acc: [0.20583333 0.45708333 0.48416667 0.48541667 0.48791667 0.48625   ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n",
      "Test acc: [0.1965 0.3713 0.3794 0.3809 0.381  0.38   0.3809 0.3806 0.3806 0.3801\n",
      " 0.3794]\n",
      "Test acc_adv: [0.018   0.0769  0.0696  0.0653  0.0644  0.06055 0.0596  0.05826 0.05695\n",
      " 0.05746 0.0552 ]\n",
      "Test acc_adv_prior: [0.08966 0.1996  0.1791  0.1677  0.1642  0.1553  0.1531  0.1489  0.1459\n",
      " 0.1473  0.1422 ]\n",
      "step: 0 \ttraining acc: [0.19291667 0.46375    0.47708333 0.47708333 0.48125    0.47958333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03458333]\n",
      "Test acc: [0.202  0.3647 0.3735 0.3716 0.3728 0.373  0.3735 0.3735 0.375  0.3745\n",
      " 0.3748]\n",
      "Test acc_adv: [0.022   0.0699  0.06226 0.05905 0.0568  0.0544  0.054   0.05347 0.0532\n",
      " 0.05307 0.05252]\n",
      "Test acc_adv_prior: [0.1019 0.1814 0.1592 0.1527 0.1465 0.1392 0.138  0.1373 0.1354 0.1357\n",
      " 0.1338]\n",
      "step: 10 \ttraining acc: [0.20291667 0.455      0.46708333 0.47333333 0.4725     0.47708333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n",
      "step: 20 \ttraining acc: [0.22208333 0.475      0.49375    0.49375    0.48916667 0.49208333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03416667]\n",
      "step: 30 \ttraining acc: [0.19916667 0.44208333 0.45916667 0.46625    0.46625    0.46583333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02583333]\n",
      "step: 40 \ttraining acc: [0.17416667 0.43208333 0.44708333 0.45       0.45333333 0.45333333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "step: 50 \ttraining acc: [0.19458333 0.44125    0.45125    0.45666667 0.45833333 0.46125   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02083333]\n",
      "step: 60 \ttraining acc: [0.21416667 0.44916667 0.45875    0.46166667 0.47       0.4725    ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03291667]\n",
      "Test acc: [0.1964 0.36   0.3708 0.3733 0.3733 0.3745 0.3735 0.3735 0.3735 0.3726\n",
      " 0.3723]\n",
      "Test acc_adv: [0.02147 0.07587 0.06256 0.05786 0.05612 0.05347 0.05252 0.05106 0.0508\n",
      " 0.0504  0.05106]\n",
      "Test acc_adv_prior: [0.10364 0.2054  0.1642  0.1493  0.1465  0.1392  0.138   0.1326  0.132\n",
      " 0.131   0.133  ]\n",
      "step: 70 \ttraining acc: [0.23875    0.48708333 0.49541667 0.5        0.50208333 0.50458333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04291667]\n",
      "step: 80 \ttraining acc: [0.23       0.47916667 0.49083333 0.49208333 0.48958333 0.48916667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03083333]\n",
      "step: 90 \ttraining acc: [0.21333333 0.48333333 0.49333333 0.49791667 0.49583333 0.49958333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04833333]\n",
      "step: 100 \ttraining acc: [0.19083333 0.43833333 0.45625    0.45458333 0.45625    0.45625   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02458333]\n",
      "step: 110 \ttraining acc: [0.21541667 0.46583333 0.46958333 0.47333333 0.47458333 0.4725    ]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0325]\n",
      "step: 120 \ttraining acc: [0.20333333 0.49875    0.51041667 0.51416667 0.515      0.5175    ]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05875]\n",
      "Test acc: [0.2032 0.3616 0.3616 0.3635 0.3616 0.3616 0.3635 0.3628 0.3623 0.3625\n",
      " 0.364 ]\n",
      "Test acc_adv: [0.01933 0.0733  0.06506 0.05988 0.058   0.05588 0.054   0.054   0.0528\n",
      " 0.05295 0.05133]\n",
      "Test acc_adv_prior: [0.0903 0.1985 0.1749 0.1587 0.1544 0.1481 0.1434 0.1427 0.1401 0.1403\n",
      " 0.1343]\n",
      "step: 0 \ttraining acc: [0.18291667 0.45708333 0.47375    0.48125    0.48166667 0.48416667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03541667]\n",
      "Test acc: [0.2095 0.3674 0.3767 0.3767 0.3743 0.373  0.372  0.3723 0.3726 0.3723\n",
      " 0.3716]\n",
      "Test acc_adv: [0.02107 0.0776  0.06415 0.05774 0.05652 0.05374 0.05212 0.05145 0.05145\n",
      " 0.0508  0.05014]\n",
      "Test acc_adv_prior: [0.0957 0.2004 0.1622 0.1449 0.1428 0.1362 0.1327 0.131  0.1311 0.1292\n",
      " 0.1274]\n",
      "step: 10 \ttraining acc: [0.21708333 0.485      0.50583333 0.51083333 0.50875    0.51083333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03791667]\n",
      "step: 20 \ttraining acc: [0.19458333 0.45666667 0.4675     0.47541667 0.47291667 0.47      ]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03875]\n",
      "step: 30 \ttraining acc: [0.19958333 0.45708333 0.47375    0.47583333 0.4825     0.48333333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "step: 40 \ttraining acc: [0.18916667 0.47916667 0.49291667 0.49125    0.49291667 0.49333333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03208333]\n",
      "step: 50 \ttraining acc: [0.2275     0.45583333 0.465      0.46833333 0.46833333 0.47083333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04291667]\n",
      "step: 60 \ttraining acc: [0.18458333 0.47583333 0.49583333 0.49708333 0.49875    0.50125   ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03541667]\n",
      "Test acc: [0.2014 0.3638 0.3723 0.3728 0.3733 0.3738 0.3735 0.374  0.374  0.373\n",
      " 0.373 ]\n",
      "Test acc_adv: [0.022   0.08215 0.066   0.06    0.05612 0.0544  0.0516  0.05066 0.05066\n",
      " 0.05    0.0492 ]\n",
      "Test acc_adv_prior: [0.10956 0.2175  0.1702  0.1544  0.1436  0.1376  0.1312  0.1289  0.1287\n",
      " 0.128   0.1256 ]\n",
      "step: 70 \ttraining acc: [0.19875    0.46166667 0.47666667 0.48291667 0.48458333 0.48833333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02833333]\n",
      "step: 80 \ttraining acc: [0.18541667 0.45041667 0.47208333 0.4725     0.47166667 0.47375   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01833333]\n",
      "step: 90 \ttraining acc: [0.17541667 0.45208333 0.46416667 0.46625    0.46541667 0.46458333]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04625]\n",
      "step: 100 \ttraining acc: [0.17125    0.41125    0.43458333 0.4425     0.445      0.44583333]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "step: 110 \ttraining acc: [0.19041667 0.46625    0.48208333 0.48708333 0.48958333 0.49208333]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03375]\n",
      "step: 120 \ttraining acc: [0.22458333 0.45666667 0.47583333 0.47875    0.48041667 0.47791667]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03125]\n",
      "Test acc: [0.2035 0.3577 0.3665 0.368  0.365  0.3652 0.3655 0.365  0.365  0.3652\n",
      " 0.366 ]\n",
      "Test acc_adv: [0.028   0.0727  0.06    0.0552  0.05307 0.0516  0.0512  0.05066 0.04935\n",
      " 0.04987 0.04868]\n",
      "Test acc_adv_prior: [0.1337 0.1998 0.1602 0.1475 0.1423 0.1398 0.1381 0.1362 0.133  0.1349\n",
      " 0.132 ]\n",
      "step: 0 \ttraining acc: [0.20375    0.44625    0.45833333 0.45875    0.46333333 0.46375   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03166667]\n",
      "Test acc: [0.2039 0.361  0.3743 0.3794 0.379  0.3809 0.38   0.3806 0.381  0.3806\n",
      " 0.381 ]\n",
      "Test acc_adv: [0.02254 0.0763  0.06186 0.05652 0.056   0.05334 0.05133 0.05133 0.0512\n",
      " 0.04974 0.0492 ]\n",
      "Test acc_adv_prior: [0.1034 0.2048 0.1603 0.1447 0.1439 0.1361 0.1315 0.1312 0.1313 0.1278\n",
      " 0.1262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 \ttraining acc: [0.18541667 0.4625     0.4775     0.47833333 0.48166667 0.48333333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03666667]\n",
      "step: 20 \ttraining acc: [0.18916667 0.46666667 0.47458333 0.47833333 0.48       0.47958333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01791667]\n",
      "step: 30 \ttraining acc: [0.17583333 0.43541667 0.44958333 0.45166667 0.45708333 0.45708333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03375]\n",
      "step: 40 \ttraining acc: [0.18041667 0.44333333 0.45666667 0.46125    0.45958333 0.45875   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02458333]\n",
      "step: 50 \ttraining acc: [0.19083333 0.49083333 0.50333333 0.50166667 0.50208333 0.50125   ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03375]\n",
      "step: 60 \ttraining acc: [0.20208333 0.46625    0.49208333 0.495      0.49458333 0.49458333]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02875]\n",
      "Test acc: [0.1989 0.357  0.3718 0.376  0.3726 0.3726 0.3706 0.371  0.372  0.3718\n",
      " 0.3723]\n",
      "Test acc_adv: [0.01654 0.0709  0.05746 0.0512  0.04892 0.04666 0.04666 0.04575 0.04453\n",
      " 0.04373 0.04266]\n",
      "Test acc_adv_prior: [0.0749  0.1915  0.1511  0.1334  0.1293  0.1215  0.12195 0.12    0.11646\n",
      " 0.1146  0.11096]\n",
      "step: 70 \ttraining acc: [0.19791667 0.45541667 0.4675     0.46833333 0.47458333 0.475     ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03125]\n",
      "step: 80 \ttraining acc: [0.19666667 0.50041667 0.51416667 0.5175     0.52375    0.52291667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03916667]\n",
      "step: 90 \ttraining acc: [0.195      0.45333333 0.46458333 0.46833333 0.46833333 0.46916667]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03125]\n",
      "step: 100 \ttraining acc: [0.19416667 0.46416667 0.48       0.47708333 0.475      0.47416667]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02375]\n",
      "step: 110 \ttraining acc: [0.18541667 0.48625    0.50291667 0.51       0.50916667 0.51583333]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03375]\n",
      "step: 120 \ttraining acc: [0.19291667 0.47541667 0.49791667 0.50666667 0.51125    0.51541667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04333333]\n",
      "Test acc: [0.1909 0.3616 0.3755 0.377  0.3757 0.3755 0.3765 0.3752 0.3748 0.375\n",
      " 0.374 ]\n",
      "Test acc_adv: [0.0224  0.0768  0.05948 0.05212 0.04907 0.04614 0.0468  0.04587 0.04626\n",
      " 0.04626 0.0448 ]\n",
      "Test acc_adv_prior: [0.10126 0.2037  0.1549  0.1343  0.1271  0.1205  0.1214  0.1196  0.1205\n",
      " 0.11993 0.1163 ]\n",
      "step: 0 \ttraining acc: [0.20416667 0.48666667 0.51041667 0.52041667 0.52375    0.52625   ]\n",
      "step: 0 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.03]\n",
      "Test acc: [0.1938 0.3547 0.3687 0.373  0.3726 0.3726 0.3718 0.3718 0.3728 0.3726\n",
      " 0.3733]\n",
      "Test acc_adv: [0.01907 0.0652  0.05386 0.04974 0.04745 0.0456  0.04626 0.04547 0.04428\n",
      " 0.0452  0.04306]\n",
      "Test acc_adv_prior: [0.0954  0.1792  0.1431  0.1295  0.1243  0.1186  0.12054 0.1184  0.11475\n",
      " 0.1172  0.111  ]\n",
      "step: 10 \ttraining acc: [0.19583333 0.49458333 0.50333333 0.50333333 0.50375    0.50666667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02833333]\n",
      "step: 20 \ttraining acc: [0.19291667 0.45666667 0.4625     0.46458333 0.46583333 0.46708333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "step: 30 \ttraining acc: [0.20666667 0.45       0.45791667 0.46       0.4625     0.46291667]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02125]\n",
      "step: 40 \ttraining acc: [0.17458333 0.44875    0.46541667 0.46958333 0.46833333 0.47083333]\n",
      "step: 40 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.025]\n",
      "step: 50 \ttraining acc: [0.19833333 0.48666667 0.50333333 0.50875    0.51041667 0.51375   ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04166667]\n",
      "step: 60 \ttraining acc: [0.20625    0.46833333 0.4825     0.48791667 0.49       0.49083333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "Test acc: [0.1931 0.369  0.3809 0.3806 0.3792 0.379  0.3772 0.376  0.375  0.3745\n",
      " 0.3745]\n",
      "Test acc_adv: [0.0096  0.06415 0.05627 0.05252 0.0536  0.05145 0.04987 0.05    0.05\n",
      " 0.0488  0.04785]\n",
      "Test acc_adv_prior: [0.04874 0.1677  0.1426  0.1328  0.1355  0.1301  0.1265  0.1279  0.1289\n",
      " 0.1255  0.1235 ]\n",
      "step: 70 \ttraining acc: [0.19625    0.49291667 0.49958333 0.505      0.5125     0.50916667]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04125]\n",
      "step: 80 \ttraining acc: [0.19166667 0.44958333 0.46166667 0.465      0.46958333 0.46833333]\n",
      "step: 80 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0325]\n",
      "step: 90 \ttraining acc: [0.19666667 0.47083333 0.4825     0.4875     0.48708333 0.48583333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03458333]\n",
      "step: 100 \ttraining acc: [0.21       0.49916667 0.51291667 0.51416667 0.5125     0.50958333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02333333]\n",
      "step: 110 \ttraining acc: [0.1925     0.48333333 0.48916667 0.49375    0.495      0.49458333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04083333]\n",
      "step: 120 \ttraining acc: [0.18666667 0.46541667 0.48       0.48583333 0.48625    0.48833333]\n",
      "step: 120 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0375]\n",
      "Test acc: [0.1975 0.3528 0.364  0.365  0.3677 0.368  0.367  0.3665 0.3674 0.3674\n",
      " 0.3682]\n",
      "Test acc_adv: [0.01627 0.06226 0.0492  0.04532 0.04373 0.04333 0.04266 0.04214 0.04227\n",
      " 0.04147 0.04053]\n",
      "Test acc_adv_prior: [0.0795  0.1683  0.1298  0.11926 0.1143  0.1133  0.11127 0.1106  0.1104\n",
      " 0.1086  0.1063 ]\n",
      "step: 0 \ttraining acc: [0.18       0.47333333 0.49375    0.49958333 0.50125    0.50125   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02958333]\n",
      "Test acc: [0.1898 0.3657 0.3748 0.375  0.376  0.3745 0.3733 0.3718 0.3716 0.3716\n",
      " 0.3716]\n",
      "Test acc_adv: [0.01387 0.0632  0.05334 0.04947 0.04706 0.04654 0.0452  0.04626 0.04346\n",
      " 0.04373 0.04385]\n",
      "Test acc_adv_prior: [0.07306 0.1655  0.137   0.1267  0.1217  0.11975 0.11743 0.1208  0.113\n",
      " 0.11316 0.1139 ]\n",
      "step: 10 \ttraining acc: [0.19541667 0.495      0.50458333 0.50791667 0.51083333 0.51166667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03458333]\n",
      "step: 20 \ttraining acc: [0.22708333 0.4825     0.50291667 0.50666667 0.50791667 0.51208333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05041667]\n",
      "step: 30 \ttraining acc: [0.19791667 0.46291667 0.48958333 0.49125    0.49333333 0.49291667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "step: 40 \ttraining acc: [0.19041667 0.48083333 0.50083333 0.505      0.50875    0.50958333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02958333]\n",
      "step: 50 \ttraining acc: [0.18833333 0.48458333 0.50416667 0.50708333 0.51083333 0.50916667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04666667]\n",
      "step: 60 \ttraining acc: [0.20083333 0.47708333 0.47875    0.47916667 0.47875    0.48083333]\n",
      "step: 60 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.03]\n",
      "Test acc: [0.2037 0.3687 0.3818 0.3838 0.3835 0.3826 0.3818 0.381  0.3818 0.382\n",
      " 0.381 ]\n",
      "Test acc_adv: [0.026   0.07666 0.05893 0.05414 0.0504  0.0492  0.04852 0.04694 0.04666\n",
      " 0.04733 0.04614]\n",
      "Test acc_adv_prior: [0.1238  0.2025  0.1487  0.1351  0.1268  0.12396 0.12274 0.1189  0.1177\n",
      " 0.1183  0.1164 ]\n",
      "step: 70 \ttraining acc: [0.21       0.50583333 0.51666667 0.52041667 0.52       0.51791667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03583333]\n",
      "step: 80 \ttraining acc: [0.2275     0.51125    0.51958333 0.52125    0.52083333 0.52375   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02666667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 90 \ttraining acc: [0.22166667 0.44875    0.46791667 0.4775     0.47916667 0.48083333]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0225]\n",
      "step: 100 \ttraining acc: [0.20791667 0.46916667 0.48583333 0.49083333 0.49291667 0.495     ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01958333]\n",
      "step: 110 \ttraining acc: [0.17833333 0.49375    0.49833333 0.50125    0.50166667 0.50041667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01666667]\n",
      "step: 120 \ttraining acc: [0.21041667 0.42833333 0.445      0.44166667 0.44208333 0.44208333]\n",
      "step: 120 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.025]\n",
      "Test acc: [0.1969 0.37   0.3743 0.3745 0.3743 0.3735 0.3745 0.373  0.3718 0.3716\n",
      " 0.371 ]\n",
      "Test acc_adv: [0.022   0.06384 0.05212 0.0516  0.04813 0.04626 0.046   0.04575 0.04587\n",
      " 0.04428 0.0456 ]\n",
      "Test acc_adv_prior: [0.10913 0.167   0.1346  0.1326  0.1218  0.1182  0.1174  0.11743 0.1185\n",
      " 0.1144  0.1191 ]\n",
      "step: 0 \ttraining acc: [0.19958333 0.49875    0.52333333 0.52083333 0.525      0.52458333]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02875]\n",
      "Test acc: [0.2037 0.3635 0.3672 0.371  0.3716 0.37   0.3682 0.3687 0.368  0.3677\n",
      " 0.3672]\n",
      "Test acc_adv: [0.01866 0.06186 0.05173 0.04935 0.04828 0.04547 0.0452  0.0444  0.04453\n",
      " 0.04492 0.04266]\n",
      "Test acc_adv_prior: [0.08777 0.164   0.1356  0.1268  0.12494 0.11914 0.11816 0.1167  0.11615\n",
      " 0.11786 0.1115 ]\n",
      "step: 10 \ttraining acc: [0.19875    0.49458333 0.50166667 0.5075     0.50666667 0.50791667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n",
      "step: 20 \ttraining acc: [0.17333333 0.46208333 0.47541667 0.4775     0.47708333 0.48125   ]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03875]\n",
      "step: 30 \ttraining acc: [0.18666667 0.49291667 0.50791667 0.50958333 0.51458333 0.51666667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03041667]\n",
      "step: 40 \ttraining acc: [0.22       0.50041667 0.51       0.50875    0.50958333 0.50875   ]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03125]\n",
      "step: 50 \ttraining acc: [0.21125    0.47083333 0.47875    0.47958333 0.47791667 0.47625   ]\n",
      "step: 50 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.03]\n",
      "step: 60 \ttraining acc: [0.20291667 0.45375    0.47541667 0.48625    0.48916667 0.49166667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03583333]\n",
      "Test acc: [0.2023 0.361  0.373  0.379  0.3804 0.3806 0.3806 0.3801 0.38   0.3792\n",
      " 0.3782]\n",
      "Test acc_adv: [0.01987 0.06107 0.05054 0.0476  0.04547 0.0444  0.04346 0.04227 0.04266\n",
      " 0.0428  0.04187]\n",
      "Test acc_adv_prior: [0.0912  0.1625  0.1307  0.12085 0.1143  0.11194 0.1091  0.10596 0.1073\n",
      " 0.1079  0.1056 ]\n",
      "step: 70 \ttraining acc: [0.18916667 0.46083333 0.47708333 0.48041667 0.4825     0.48666667]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02375]\n",
      "step: 80 \ttraining acc: [0.25625    0.47208333 0.485      0.48583333 0.48666667 0.48916667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03458333]\n",
      "step: 90 \ttraining acc: [0.18416667 0.48708333 0.50833333 0.51416667 0.51541667 0.51458333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04791667]\n",
      "step: 100 \ttraining acc: [0.19833333 0.52833333 0.54166667 0.5425     0.54333333 0.54416667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03791667]\n",
      "step: 110 \ttraining acc: [0.18291667 0.44291667 0.4525     0.45708333 0.45458333 0.44958333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "step: 120 \ttraining acc: [0.18875    0.4675     0.47833333 0.48458333 0.4875     0.48541667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02166667]\n",
      "Test acc: [0.1917 0.361  0.3694 0.3723 0.3726 0.371  0.3708 0.37   0.3699 0.3699\n",
      " 0.3696]\n",
      "Test acc_adv: [0.010666 0.0564   0.04694  0.0448   0.04108  0.04068  0.04092  0.04025\n",
      " 0.0392   0.03986  0.03946 ]\n",
      "Test acc_adv_prior: [0.0549  0.1506  0.122   0.1146  0.1048  0.1044  0.1054  0.1033  0.1012\n",
      " 0.10236 0.10114]\n",
      "step: 0 \ttraining acc: [0.2025     0.48291667 0.495      0.49458333 0.49666667 0.50041667]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "Test acc: [0.2079 0.364  0.372  0.369  0.3699 0.3682 0.3691 0.3699 0.3694 0.37\n",
      " 0.3691]\n",
      "Test acc_adv: [0.01613 0.06775 0.05612 0.0516  0.04813 0.04813 0.0452  0.04507 0.0452\n",
      " 0.0448  0.04373]\n",
      "Test acc_adv_prior: [0.07135 0.1769  0.1422  0.1323  0.1239  0.1243  0.1172  0.1166  0.1166\n",
      " 0.1164  0.1132 ]\n",
      "step: 10 \ttraining acc: [0.19       0.50708333 0.51666667 0.51916667 0.51916667 0.52041667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02666667]\n",
      "step: 20 \ttraining acc: [0.21625    0.47041667 0.46833333 0.47166667 0.47583333 0.47458333]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.04125]\n",
      "step: 30 \ttraining acc: [0.20541667 0.47791667 0.49083333 0.49041667 0.49083333 0.49291667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04333333]\n",
      "step: 40 \ttraining acc: [0.20666667 0.4675     0.47708333 0.48083333 0.4825     0.485     ]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.01875]\n",
      "step: 50 \ttraining acc: [0.21375    0.50458333 0.51833333 0.51958333 0.52166667 0.51833333]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.03375]\n",
      "step: 60 \ttraining acc: [0.19916667 0.48375    0.50125    0.50333333 0.50125    0.49916667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02666667]\n",
      "Test acc: [0.2096 0.3696 0.3752 0.3767 0.378  0.3804 0.3792 0.3804 0.381  0.3809\n",
      " 0.3806]\n",
      "Test acc_adv: [0.02614 0.06134 0.05252 0.0476  0.04413 0.0412  0.04068 0.03934 0.03906\n",
      " 0.03854 0.03854]\n",
      "Test acc_adv_prior: [0.1185  0.1605  0.1357  0.12286 0.1127  0.10504 0.1054  0.10144 0.09973\n",
      " 0.09955 0.099  ]\n",
      "step: 70 \ttraining acc: [0.18       0.47958333 0.49541667 0.49416667 0.49583333 0.49625   ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02541667]\n",
      "step: 80 \ttraining acc: [0.20791667 0.48791667 0.51166667 0.52041667 0.52625    0.53041667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03666667]\n",
      "step: 90 \ttraining acc: [0.20916667 0.525      0.53458333 0.53708333 0.53875    0.54375   ]\n",
      "step: 90 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0425]\n",
      "step: 100 \ttraining acc: [0.18708333 0.49083333 0.50625    0.51916667 0.52333333 0.52208333]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "step: 110 \ttraining acc: [0.21666667 0.45       0.46875    0.46666667 0.46333333 0.46291667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01208333]\n",
      "step: 120 \ttraining acc: [0.1775     0.455      0.47541667 0.47791667 0.48       0.47916667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02541667]\n",
      "Test acc: [0.2046 0.3472 0.367  0.3674 0.369  0.369  0.3687 0.3684 0.368  0.368\n",
      " 0.368 ]\n",
      "Test acc_adv: [0.02173 0.078   0.05933 0.05386 0.04987 0.04745 0.04575 0.0456  0.04532\n",
      " 0.04333 0.044  ]\n",
      "Test acc_adv_prior: [0.09863 0.2155  0.1561  0.1405  0.1301  0.12225 0.1183  0.11786 0.1168\n",
      " 0.1112  0.1133 ]\n",
      "step: 0 \ttraining acc: [0.18041667 0.48333333 0.49125    0.49375    0.49791667 0.50125   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03083333]\n",
      "Test acc: [0.1771 0.3545 0.3672 0.3672 0.3635 0.3655 0.3665 0.3672 0.3667 0.3672\n",
      " 0.3665]\n",
      "Test acc_adv: [0.02066 0.06854 0.0572  0.05414 0.05093 0.0472  0.04492 0.04468 0.044\n",
      " 0.0432  0.04266]\n",
      "Test acc_adv_prior: [0.1052  0.1859  0.1506  0.1427  0.136   0.1256  0.1192  0.1181  0.11694\n",
      " 0.1144  0.1131 ]\n",
      "step: 10 \ttraining acc: [0.2        0.465      0.47583333 0.47958333 0.48291667 0.48791667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 20 \ttraining acc: [0.19208333 0.47125    0.50208333 0.5075     0.50875    0.50708333]\n",
      "step: 20 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02125]\n",
      "step: 30 \ttraining acc: [0.22083333 0.48833333 0.49708333 0.5025     0.50458333 0.50541667]\n",
      "step: 30 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.025]\n",
      "step: 40 \ttraining acc: [0.23166667 0.4725     0.485      0.4875     0.48833333 0.49208333]\n",
      "step: 40 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.03]\n",
      "step: 50 \ttraining acc: [0.1975     0.48666667 0.50208333 0.51       0.51166667 0.51333333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "step: 60 \ttraining acc: [0.20416667 0.46833333 0.48291667 0.4875     0.49625    0.5       ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01666667]\n",
      "Test acc: [0.1866 0.3562 0.3674 0.3716 0.3706 0.3718 0.371  0.3696 0.369  0.3687\n",
      " 0.3684]\n",
      "Test acc_adv: [0.012   0.05853 0.0472  0.04547 0.04385 0.04346 0.04294 0.04227 0.0428\n",
      " 0.04306 0.04175]\n",
      "Test acc_adv_prior: [0.0684  0.1594  0.12415 0.1178  0.11395 0.1126  0.11145 0.10944 0.1122\n",
      " 0.11255 0.1096 ]\n",
      "step: 70 \ttraining acc: [0.20875    0.4925     0.50375    0.50541667 0.50625    0.5025    ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01666667]\n",
      "step: 80 \ttraining acc: [0.20416667 0.46625    0.4725     0.47375    0.47458333 0.48041667]\n",
      "step: 80 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.04]\n",
      "step: 90 \ttraining acc: [0.205      0.5125     0.52166667 0.525      0.52458333 0.52375   ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "step: 100 \ttraining acc: [0.18       0.44       0.44583333 0.45041667 0.45166667 0.45416667]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "step: 110 \ttraining acc: [0.18       0.47791667 0.49416667 0.4975     0.49958333 0.49791667]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0375]\n",
      "step: 120 \ttraining acc: [0.20416667 0.50333333 0.51083333 0.51375    0.51791667 0.51791667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.04458333]\n",
      "Test acc: [0.1937 0.3674 0.3691 0.3716 0.3718 0.3713 0.3713 0.3704 0.3706 0.3706\n",
      " 0.3704]\n",
      "Test acc_adv: [0.01293 0.06616 0.0504  0.04468 0.04266 0.04013 0.04053 0.03906 0.03787\n",
      " 0.03894 0.03815]\n",
      "Test acc_adv_prior: [0.06113 0.1715  0.1299  0.11487 0.10876 0.10187 0.1029  0.0993  0.0968\n",
      " 0.0997  0.09705]\n",
      "step: 0 \ttraining acc: [0.16625    0.47375    0.48541667 0.48916667 0.48916667 0.48833333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "Test acc: [0.197  0.3662 0.3762 0.3767 0.3767 0.3774 0.3774 0.3765 0.3762 0.3774\n",
      " 0.3774]\n",
      "Test acc_adv: [0.01826 0.05865 0.04745 0.04175 0.04013 0.03708 0.03815 0.03653 0.03625\n",
      " 0.03494 0.03546]\n",
      "Test acc_adv_prior: [0.0787  0.1509  0.11694 0.1037  0.09985 0.0925  0.0954  0.0908  0.0909\n",
      " 0.08704 0.0886 ]\n",
      "step: 10 \ttraining acc: [0.19666667 0.50541667 0.52791667 0.525      0.52583333 0.525     ]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02625]\n",
      "step: 20 \ttraining acc: [0.17541667 0.50166667 0.50625    0.50916667 0.51041667 0.51041667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03708333]\n",
      "step: 30 \ttraining acc: [0.21416667 0.475      0.48208333 0.48958333 0.49625    0.49875   ]\n",
      "step: 30 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0275]\n",
      "step: 40 \ttraining acc: [0.17708333 0.48625    0.49833333 0.49833333 0.49708333 0.50125   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02958333]\n",
      "step: 50 \ttraining acc: [0.22416667 0.48       0.48791667 0.48875    0.48791667 0.48791667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03041667]\n",
      "step: 60 \ttraining acc: [0.18208333 0.47208333 0.47958333 0.47708333 0.47375    0.47625   ]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.01875]\n",
      "Test acc: [0.2024 0.3726 0.3733 0.3723 0.372  0.3723 0.371  0.372  0.371  0.3718\n",
      " 0.3716]\n",
      "Test acc_adv: [0.01387 0.04987 0.0432  0.04108 0.0388  0.03946 0.0396  0.03827 0.03772\n",
      " 0.03894 0.03772]\n",
      "Test acc_adv_prior: [0.0645  0.1288  0.11    0.10535 0.0999  0.10144 0.10223 0.0986  0.0968\n",
      " 0.1     0.09735]\n",
      "step: 70 \ttraining acc: [0.2025     0.46416667 0.47333333 0.48125    0.48333333 0.48125   ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.02375]\n",
      "step: 80 \ttraining acc: [0.20875    0.48708333 0.50375    0.50625    0.51208333 0.5125    ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02666667]\n",
      "step: 90 \ttraining acc: [0.20791667 0.49291667 0.5        0.50166667 0.50291667 0.50416667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03166667]\n",
      "step: 100 \ttraining acc: [0.20083333 0.47833333 0.49541667 0.49541667 0.4975     0.49666667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "step: 110 \ttraining acc: [0.22916667 0.47458333 0.49041667 0.49416667 0.49       0.49083333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01833333]\n",
      "step: 120 \ttraining acc: [0.19708333 0.475      0.48166667 0.4825     0.48083333 0.48125   ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02416667]\n",
      "Test acc: [0.2101 0.3667 0.3706 0.3733 0.3745 0.374  0.3738 0.3735 0.3735 0.3726\n",
      " 0.372 ]\n",
      "Test acc_adv: [0.01213 0.04935 0.04413 0.0428  0.0412  0.0404  0.03906 0.04053 0.04025\n",
      " 0.0404  0.03867]\n",
      "Test acc_adv_prior: [0.05487 0.1279  0.1136  0.10974 0.10583 0.1038  0.10065 0.10364 0.10364\n",
      " 0.10394 0.0996 ]\n",
      "step: 0 \ttraining acc: [0.18041667 0.46875    0.48875    0.49208333 0.49833333 0.5025    ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02208333]\n",
      "Test acc: [0.2118 0.3633 0.373  0.374  0.3735 0.3733 0.3738 0.375  0.3752 0.3752\n",
      " 0.375 ]\n",
      "Test acc_adv: [0.01706 0.05505 0.04785 0.04492 0.04227 0.04    0.04    0.03894 0.03827\n",
      " 0.0388  0.03986]\n",
      "Test acc_adv_prior: [0.07104 0.1443  0.12225 0.1152  0.1085  0.1021  0.10236 0.0993  0.09717\n",
      " 0.0988  0.10126]\n",
      "step: 10 \ttraining acc: [0.20541667 0.48333333 0.49333333 0.50166667 0.50083333 0.50208333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02083333]\n",
      "step: 20 \ttraining acc: [0.22125    0.50833333 0.51458333 0.515      0.5175     0.5175    ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02541667]\n",
      "step: 30 \ttraining acc: [0.19625    0.4675     0.48125    0.48416667 0.48625    0.48625   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02583333]\n",
      "step: 40 \ttraining acc: [0.19208333 0.475      0.47875    0.48333333 0.48708333 0.48541667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02708333]\n",
      "step: 50 \ttraining acc: [0.1775     0.45625    0.45791667 0.46041667 0.4575     0.45833333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02208333]\n",
      "step: 60 \ttraining acc: [0.18625    0.48416667 0.4975     0.49875    0.49958333 0.50083333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02291667]\n",
      "Test acc: [0.2056 0.3674 0.374  0.3745 0.3745 0.3738 0.374  0.3748 0.3765 0.3765\n",
      " 0.3762]\n",
      "Test acc_adv: [0.01627 0.0584  0.0448  0.03946 0.03815 0.03693 0.03772 0.03665 0.03574\n",
      " 0.03625 0.03574]\n",
      "Test acc_adv_prior: [0.07605 0.153   0.1147  0.1009  0.0978  0.0958  0.0971  0.0941  0.09106\n",
      " 0.09216 0.0911 ]\n",
      "step: 70 \ttraining acc: [0.21166667 0.50416667 0.51833333 0.52416667 0.52541667 0.52541667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03666667]\n",
      "step: 80 \ttraining acc: [0.18625    0.47041667 0.47791667 0.47791667 0.47583333 0.47875   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.02041667]\n",
      "step: 90 \ttraining acc: [0.18666667 0.45916667 0.4675     0.46916667 0.47125    0.47041667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.03333333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100 \ttraining acc: [0.21791667 0.48708333 0.50083333 0.49666667 0.49791667 0.49625   ]\n",
      "step: 100 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0225]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12260\\2849002646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12260\\2849002646.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mx_spt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_qry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_spt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0maccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs_adv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_q_adv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_spt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_spt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_qry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\코드\\R-MAML\\Research\\aRUB+RMAML\\metapgd.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_spt, y_spt, x_qry, y_qry)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;31m# [setsz]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[0mpred_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_qry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[0mcorrects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "import time\n",
    "\n",
    "#from ANIP import Meta\n",
    "#from metafgsmanil import Meta\n",
    "#from metafgsm import Meta\n",
    "#from MAMLMeta import Meta\n",
    "#from meta import Meta\n",
    "#from Adv_Quer import Meta\n",
    "#from metafgsmnewnew import Meta\n",
    "from metapgd import Meta\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('../run-imgsz28-4000/pgd-metalr=0.003-advlr=0.0002', comment='pgd-metalr=0.003-advlr=0.0002')\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0] \n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "def main():\n",
    "    \n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "    '''\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 5 * 5])\n",
    "    ]\n",
    "    '''\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 2 * 2])\n",
    "    ]\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    maml = Meta(args, config, device).to(device)\n",
    "    \n",
    "    \n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    #filename = 'mamlfgsmeps4_2.pt'\n",
    "    filename = 'mamlfgsmeps2_8.pt'\n",
    "    #maml = Meta(args, config).to(device)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        maml.net.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "    \n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('../../dataset/', mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                        k_query=args.k_qry,\n",
    "                        batchsz=4000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../../dataset/', mode='test', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "    tot_step = -args.task_num\n",
    "    #adv_loss_on = True\n",
    "    for epoch in range(100):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db): # 0~124 -> batch 32일 때\n",
    "            tot_step = tot_step + args.task_num\n",
    "            '''\n",
    "            if step == 1:\n",
    "                t = time.perf_counter()\n",
    "            if step == 499:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "            if step == 501:\n",
    "                t = time.perf_counter()\n",
    "            if step == 999:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "            '''\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs, accs_adv, loss_q, loss_q_adv = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "                print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "                writer.add_scalar(\"acc/train\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/train\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"loss/train\", loss_q,tot_step)\n",
    "                writer.add_scalar(\"loss_adv/train\", loss_q_adv,tot_step)\n",
    "                state = {'epoch': epoch, 'step': step, 'state_dict': maml.net.state_dict()}\n",
    "                torch.save(state, 'mamlfgsmeps4_2.pt')\n",
    "            \n",
    "            if step % 60 == 0:  # evaluation -> 학습에는 전혀 영향을 주지 않음, copy network를 사용하므로\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                accsadv_all_test = []\n",
    "                accsadvpr_all_test = []\n",
    "                loss_all_test = []\n",
    "                loss_adv_all_test = []\n",
    "                \n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    accs, accs_adv, accs_adv_prior, loss_q, loss_q_adv = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "                    accsadv_all_test.append(accs_adv)\n",
    "                    accsadvpr_all_test.append(accs_adv_prior)\n",
    "                    loss_all_test.append(loss_q.item())\n",
    "                    loss_adv_all_test.append(loss_q_adv.item())\n",
    "                    \n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "                loss_q = np.array(loss_all_test).mean()\n",
    "                loss_q_adv = np.array(loss_adv_all_test).mean()\n",
    "                print('Test acc:', accs)\n",
    "                print('Test acc_adv:', accs_adv)\n",
    "                print('Test acc_adv_prior:', accs_adv_prior)\n",
    "                writer.add_scalar(\"acc/test\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/test\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv_prior/test\", accs_adv_prior[-1],tot_step)\n",
    "                writer.add_scalar(\"loss/test\", loss_q,tot_step)\n",
    "                writer.add_scalar(\"loss_adv/test\", loss_q_adv,tot_step)\n",
    "                if step==120:\n",
    "                    writer.add_scalar(\"acc/test_epoch\", accs[-1],epoch)\n",
    "                    writer.add_scalar(\"acc_adv/test_epoch\", accs_adv[-1],epoch)\n",
    "                    writer.add_scalar(\"loss/epoch\", loss_q, epoch)\n",
    "                    writer.add_scalar(\"loss_adv/epoch\", loss_q_adv, epoch)\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=60000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=28)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=32)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=0.001) #0.001 - 0.0002 기존\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
