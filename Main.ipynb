{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=60000, imgc=3, imgsz=28, k_qry=15, k_spt=1, meta_lr=0.001, n_way=5, task_num=32, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "init\n",
      "=> no checkpoint found at 'mamlfgsmeps2_8.pt'\n",
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:128, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.float32 of size 5x128 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.float32 of size 5 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 20229\n",
      "shuffle DB :train, b:4000, 5-way, 1-shot, 15-query, resize:28\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:28\n",
      "step: 0 \ttraining acc: [0.21458333 0.23833333 0.24875    0.24791667 0.25291667 0.25083333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.00416667]\n",
      "Test acc: [0.1945 0.213  0.223  0.222  0.2261 0.2263 0.2281 0.2274 0.2274 0.2272\n",
      " 0.2269]\n",
      "Test acc_adv: [0.0044   0.02173  0.01107  0.006668 0.005066 0.0048   0.004665 0.004\n",
      " 0.0044   0.004    0.004265]\n",
      "Test acc_adv_prior: [0.0206  0.103   0.05045 0.029   0.02092 0.01909 0.0188  0.01581 0.01753\n",
      " 0.01625 0.01735]\n",
      "step: 10 \ttraining acc: [0.1875     0.22       0.22958333 0.24083333 0.24291667 0.24541667]\n",
      "step: 10 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 20 \ttraining acc: [0.19708333 0.24125    0.26916667 0.27875    0.28333333 0.28625   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.00708333]\n",
      "step: 30 \ttraining acc: [0.21916667 0.2625     0.27875    0.28916667 0.29       0.29541667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.01666667]\n",
      "step: 40 \ttraining acc: [0.19166667 0.25125    0.27791667 0.28541667 0.28666667 0.2925    ]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0225]\n",
      "step: 50 \ttraining acc: [0.20875    0.25416667 0.29375    0.30625    0.31125    0.31958333]\n",
      "step: 50 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.0425]\n",
      "step: 60 \ttraining acc: [0.18375    0.26833333 0.30208333 0.30791667 0.31208333 0.31166667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.05583333]\n",
      "Test acc: [0.1951 0.2151 0.2404 0.2462 0.2473 0.2517 0.2522 0.2517 0.2534 0.255\n",
      " 0.2532]\n",
      "Test acc_adv: [0.01093 0.0232  0.03586 0.0468  0.05466 0.06186 0.06506 0.0676  0.0707\n",
      " 0.0727  0.07666]\n",
      "Test acc_adv_prior: [0.05618 0.1067  0.1505  0.1931  0.2222  0.2472  0.2578  0.27    0.279\n",
      " 0.284   0.3037 ]\n",
      "step: 70 \ttraining acc: [0.2125     0.265      0.28333333 0.29041667 0.3        0.30375   ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.05375]\n",
      "step: 80 \ttraining acc: [0.2025     0.27666667 0.2925     0.29416667 0.29791667 0.29875   ]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06166667]\n",
      "step: 90 \ttraining acc: [0.19833333 0.26041667 0.2875     0.29958333 0.29791667 0.30291667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.06291667]\n",
      "step: 100 \ttraining acc: [0.19041667 0.28125    0.30583333 0.31291667 0.3175     0.31833333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07458333]\n",
      "step: 110 \ttraining acc: [0.17666667 0.28166667 0.30416667 0.31791667 0.32416667 0.32875   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08916667]\n",
      "step: 120 \ttraining acc: [0.18541667 0.25708333 0.27458333 0.28291667 0.28541667 0.29      ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.07541667]\n",
      "Test acc: [0.2004 0.2297 0.2456 0.255  0.2583 0.2617 0.2607 0.2607 0.262  0.2625\n",
      " 0.2625]\n",
      "Test acc_adv: [0.01    0.03214 0.0536  0.06976 0.0797  0.08905 0.0968  0.1008  0.1039\n",
      " 0.10864 0.1128 ]\n",
      "Test acc_adv_prior: [0.04987 0.1354  0.2146  0.2725  0.3096  0.3428  0.3743  0.3909  0.3994\n",
      " 0.4175  0.4324 ]\n",
      "step: 0 \ttraining acc: [0.2125     0.29291667 0.31208333 0.31583333 0.32416667 0.32583333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08916667]\n",
      "Test acc: [0.1976 0.2269 0.2468 0.2524 0.2578 0.2595 0.261  0.2603 0.262  0.2637\n",
      " 0.2617]\n",
      "Test acc_adv: [0.01027 0.03253 0.05533 0.0736  0.08466 0.0939  0.10065 0.10706 0.11066\n",
      " 0.1147  0.1168 ]\n",
      "Test acc_adv_prior: [0.05188 0.1388  0.2216  0.286   0.3223  0.357   0.382   0.4084  0.4197\n",
      " 0.4329  0.4446 ]\n",
      "step: 10 \ttraining acc: [0.19666667 0.27833333 0.31333333 0.32       0.325      0.3275    ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08333333]\n",
      "step: 20 \ttraining acc: [0.20541667 0.26958333 0.30416667 0.30791667 0.31208333 0.31583333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08708333]\n",
      "step: 30 \ttraining acc: [0.18916667 0.27       0.29791667 0.30375    0.31041667 0.31291667]\n",
      "step: 30 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.085]\n",
      "step: 40 \ttraining acc: [0.20916667 0.2925     0.3175     0.3225     0.31958333 0.32166667]\n",
      "step: 40 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.095]\n",
      "step: 50 \ttraining acc: [0.21625    0.28291667 0.29958333 0.30041667 0.30958333 0.31375   ]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.11375]\n",
      "step: 60 \ttraining acc: [0.20041667 0.26958333 0.29291667 0.29958333 0.30125    0.30458333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.08833333]\n",
      "Test acc: [0.1979 0.2375 0.2527 0.2576 0.261  0.2642 0.2678 0.269  0.2693 0.2676\n",
      " 0.2673]\n",
      "Test acc_adv: [0.0208  0.04507 0.0696  0.0895  0.10455 0.1152  0.1217  0.1272  0.1318\n",
      " 0.135   0.1367 ]\n",
      "Test acc_adv_prior: [0.1015 0.1879 0.2725 0.3472 0.3984 0.4373 0.4558 0.474  0.4917 0.507\n",
      " 0.5146]\n",
      "step: 70 \ttraining acc: [0.21375    0.2975     0.32       0.31791667 0.31916667 0.32041667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10166667]\n",
      "step: 80 \ttraining acc: [0.19625    0.28708333 0.30875    0.31291667 0.31708333 0.32583333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.10375]\n",
      "step: 90 \ttraining acc: [0.20541667 0.29625    0.32166667 0.32041667 0.32666667 0.32916667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11041667]\n",
      "step: 100 \ttraining acc: [0.21583333 0.2675     0.29125    0.29541667 0.29833333 0.30208333]\n",
      "step: 100 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.11]\n",
      "step: 110 \ttraining acc: [0.18708333 0.28166667 0.30875    0.31458333 0.31916667 0.32375   ]\n",
      "step: 110 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.11375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 120 \ttraining acc: [0.19625    0.28166667 0.305      0.3125     0.31875    0.32291667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11166667]\n",
      "Test acc: [0.1969 0.2316 0.255  0.26   0.261  0.2612 0.2637 0.2615 0.2625 0.2617\n",
      " 0.262 ]\n",
      "Test acc_adv: [0.02347 0.05588 0.0825  0.104   0.1152  0.1266  0.1343  0.1401  0.1437\n",
      " 0.1458  0.1492 ]\n",
      "Test acc_adv_prior: [0.1194 0.2396 0.318  0.3962 0.4358 0.4778 0.504  0.5327 0.5444 0.5527\n",
      " 0.566 ]\n",
      "step: 0 \ttraining acc: [0.20375    0.29666667 0.32291667 0.33666667 0.3375     0.33458333]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1175]\n",
      "Test acc: [0.2006 0.2483 0.261  0.2668 0.2688 0.2715 0.2727 0.2742 0.2734 0.2722\n",
      " 0.2734]\n",
      "Test acc_adv: [0.02347 0.0544  0.0807  0.1036  0.1173  0.1273  0.1328  0.1405  0.1447\n",
      " 0.1488  0.1527 ]\n",
      "Test acc_adv_prior: [0.115  0.218  0.3044 0.382  0.4329 0.464  0.4827 0.509  0.525  0.542\n",
      " 0.555 ]\n",
      "step: 10 \ttraining acc: [0.19583333 0.26541667 0.28791667 0.30041667 0.3025     0.305     ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11416667]\n",
      "step: 20 \ttraining acc: [0.18541667 0.275      0.28458333 0.295      0.29416667 0.29666667]\n",
      "step: 20 \ttraining acc_adv: [0.  0.  0.  0.  0.  0.1]\n",
      "step: 30 \ttraining acc: [0.21291667 0.29041667 0.31       0.31583333 0.31583333 0.31625   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12208333]\n",
      "step: 40 \ttraining acc: [0.21916667 0.29166667 0.31541667 0.32291667 0.32333333 0.32541667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12791667]\n",
      "step: 50 \ttraining acc: [0.19875    0.2775     0.30416667 0.31125    0.31208333 0.31333333]\n",
      "step: 50 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1075]\n",
      "step: 60 \ttraining acc: [0.19791667 0.27375    0.30291667 0.31333333 0.315      0.32208333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11541667]\n",
      "Test acc: [0.2136 0.2456 0.2595 0.2656 0.267  0.2676 0.2683 0.2698 0.2705 0.2708\n",
      " 0.2712]\n",
      "Test acc_adv: [0.01854 0.05548 0.0851  0.1108  0.12427 0.1335  0.141   0.1475  0.1536\n",
      " 0.1569  0.16   ]\n",
      "Test acc_adv_prior: [0.0875 0.2214 0.3237 0.4119 0.4614 0.4941 0.5205 0.544  0.569  0.58\n",
      " 0.59  ]\n",
      "step: 70 \ttraining acc: [0.19416667 0.30208333 0.3175     0.325      0.3225     0.32333333]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.13625]\n",
      "step: 80 \ttraining acc: [0.19291667 0.29083333 0.3        0.30666667 0.3075     0.30958333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11708333]\n",
      "step: 90 \ttraining acc: [0.18166667 0.27125    0.30916667 0.31958333 0.33041667 0.3325    ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14333333]\n",
      "step: 100 \ttraining acc: [0.19625    0.26125    0.28958333 0.31       0.31375    0.32125   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.10541667]\n",
      "step: 110 \ttraining acc: [0.19041667 0.24875    0.25375    0.265      0.2725     0.2725    ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.09958333]\n",
      "step: 120 \ttraining acc: [0.19875    0.28041667 0.29166667 0.29833333 0.30125    0.30333333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11583333]\n",
      "Test acc: [0.1997 0.2489 0.2612 0.2651 0.2695 0.2698 0.2698 0.2703 0.2708 0.2708\n",
      " 0.272 ]\n",
      "Test acc_adv: [0.01866 0.05652 0.09375 0.116   0.1318  0.1416  0.1501  0.1561  0.1589\n",
      " 0.1633  0.1648 ]\n",
      "Test acc_adv_prior: [0.0908 0.2247 0.3596 0.4397 0.487  0.5225 0.554  0.575  0.585  0.6\n",
      " 0.602 ]\n",
      "step: 0 \ttraining acc: [0.19625    0.28333333 0.31833333 0.32791667 0.32833333 0.32916667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13291667]\n",
      "Test acc: [0.1953 0.2394 0.2588 0.2627 0.2632 0.2654 0.266  0.269  0.2693 0.2703\n",
      " 0.272 ]\n",
      "Test acc_adv: [0.03107 0.05972 0.0949  0.12067 0.132   0.1426  0.1504  0.1562  0.1613\n",
      " 0.1647  0.1674 ]\n",
      "Test acc_adv_prior: [0.1517 0.2413 0.359  0.4487 0.499  0.5317 0.56   0.5767 0.5938 0.606\n",
      " 0.613 ]\n",
      "step: 10 \ttraining acc: [0.20458333 0.27333333 0.30458333 0.30458333 0.3075     0.30541667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12083333]\n",
      "step: 20 \ttraining acc: [0.18708333 0.24708333 0.2825     0.28958333 0.29583333 0.295     ]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1225]\n",
      "step: 30 \ttraining acc: [0.19083333 0.28791667 0.31166667 0.31416667 0.3125     0.315     ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12541667]\n",
      "step: 40 \ttraining acc: [0.20875    0.30291667 0.30666667 0.31416667 0.31833333 0.32208333]\n",
      "step: 40 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.15]\n",
      "step: 50 \ttraining acc: [0.19416667 0.2675     0.29208333 0.29833333 0.30291667 0.30333333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12333333]\n",
      "step: 60 \ttraining acc: [0.19708333 0.28625    0.32833333 0.34291667 0.34083333 0.34666667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14666667]\n",
      "Test acc: [0.2031 0.2355 0.2585 0.2664 0.2673 0.269  0.2686 0.2703 0.2703 0.2708\n",
      " 0.2708]\n",
      "Test acc_adv: [0.04892 0.0736  0.1023  0.12494 0.138   0.1478  0.1545  0.1615  0.1649\n",
      " 0.1677  0.1697 ]\n",
      "Test acc_adv_prior: [0.237  0.3062 0.3926 0.4656 0.515  0.5474 0.5737 0.5933 0.6064 0.6147\n",
      " 0.6216]\n",
      "step: 70 \ttraining acc: [0.21666667 0.28708333 0.30333333 0.30833333 0.30666667 0.31125   ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12083333]\n",
      "step: 80 \ttraining acc: [0.18583333 0.28333333 0.2975     0.30333333 0.30958333 0.31625   ]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.13375]\n",
      "step: 90 \ttraining acc: [0.19625    0.26541667 0.28916667 0.28916667 0.29583333 0.29791667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12208333]\n",
      "step: 100 \ttraining acc: [0.20166667 0.3025     0.32541667 0.33166667 0.33666667 0.34083333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15083333]\n",
      "step: 110 \ttraining acc: [0.19583333 0.27958333 0.31125    0.31041667 0.31458333 0.31458333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13708333]\n",
      "step: 120 \ttraining acc: [0.2075     0.28166667 0.30333333 0.30916667 0.31166667 0.31541667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14458333]\n",
      "Test acc: [0.2065 0.2546 0.2698 0.2722 0.2725 0.2712 0.2708 0.2715 0.2712 0.2727\n",
      " 0.2756]\n",
      "Test acc_adv: [0.0288  0.0681  0.10266 0.1328  0.1458  0.1569  0.1648  0.1681  0.1725\n",
      " 0.176   0.1777 ]\n",
      "Test acc_adv_prior: [0.1365 0.271  0.3823 0.4895 0.534  0.577  0.607  0.6167 0.634  0.6426\n",
      " 0.643 ]\n",
      "step: 0 \ttraining acc: [0.20333333 0.30458333 0.3225     0.32375    0.33041667 0.33458333]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.13625]\n",
      "Test acc: [0.2072 0.254  0.2693 0.2734 0.2727 0.272  0.273  0.2734 0.2734 0.2725\n",
      " 0.2734]\n",
      "Test acc_adv: [0.0216  0.06256 0.10345 0.1282  0.1422  0.1537  0.1625  0.1678  0.1714\n",
      " 0.1747  0.1761 ]\n",
      "Test acc_adv_prior: [0.10223 0.2458  0.3782  0.4578  0.514   0.559   0.5884  0.607   0.619\n",
      " 0.6343  0.6377 ]\n",
      "step: 10 \ttraining acc: [0.17708333 0.29375    0.31708333 0.32666667 0.33041667 0.32916667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13458333]\n",
      "step: 20 \ttraining acc: [0.21083333 0.29458333 0.31666667 0.32125    0.32125    0.32916667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14166667]\n",
      "step: 30 \ttraining acc: [0.21875    0.31041667 0.32208333 0.32       0.32166667 0.31875   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13541667]\n",
      "step: 40 \ttraining acc: [0.19875    0.3        0.32125    0.31958333 0.32083333 0.32041667]\n",
      "step: 40 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.15]\n",
      "step: 50 \ttraining acc: [0.21125    0.31416667 0.33875    0.35166667 0.35833333 0.36166667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16416667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 60 \ttraining acc: [0.18583333 0.29333333 0.32708333 0.33625    0.33708333 0.34166667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15541667]\n",
      "Test acc: [0.1868 0.2313 0.2603 0.2693 0.2734 0.276  0.2737 0.2744 0.2764 0.2764\n",
      " 0.2769]\n",
      "Test acc_adv: [0.02907 0.06744 0.1064  0.1315  0.1464  0.1583  0.1635  0.1709  0.1754\n",
      " 0.1794  0.1823 ]\n",
      "Test acc_adv_prior: [0.1462 0.2878 0.408  0.4873 0.5366 0.571  0.597  0.62   0.6313 0.646\n",
      " 0.6567]\n",
      "step: 70 \ttraining acc: [0.20041667 0.25875    0.27791667 0.27666667 0.27791667 0.2775    ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.11333333]\n",
      "step: 80 \ttraining acc: [0.21       0.30625    0.32333333 0.33166667 0.3325     0.33166667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15958333]\n",
      "step: 90 \ttraining acc: [0.21291667 0.315      0.3325     0.33166667 0.33375    0.33541667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14666667]\n",
      "step: 100 \ttraining acc: [0.22       0.28666667 0.30916667 0.3225     0.32458333 0.33208333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14791667]\n",
      "step: 110 \ttraining acc: [0.20875    0.325      0.35541667 0.35166667 0.35291667 0.35041667]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1575]\n",
      "step: 120 \ttraining acc: [0.205      0.29166667 0.32041667 0.32833333 0.335      0.33708333]\n",
      "step: 120 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1375]\n",
      "Test acc: [0.201  0.2507 0.268  0.2734 0.2764 0.2744 0.2725 0.275  0.2766 0.2764\n",
      " 0.2769]\n",
      "Test acc_adv: [0.03665 0.0753  0.11334 0.1372  0.1542  0.1633  0.1697  0.175   0.179\n",
      " 0.1824  0.1841 ]\n",
      "Test acc_adv_prior: [0.1757 0.2964 0.4219 0.497  0.552  0.5913 0.618  0.6323 0.6426 0.655\n",
      " 0.6597]\n",
      "step: 0 \ttraining acc: [0.205      0.31083333 0.33541667 0.35083333 0.35083333 0.35041667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15291667]\n",
      "Test acc: [0.187  0.2434 0.2642 0.2683 0.272  0.2712 0.272  0.2737 0.2742 0.2756\n",
      " 0.276 ]\n",
      "Test acc_adv: [0.0284 0.0676 0.1119 0.1343 0.1494 0.1588 0.1678 0.1733 0.1764 0.1782\n",
      " 0.1819]\n",
      "Test acc_adv_prior: [0.1519 0.2725 0.4185 0.4946 0.5464 0.5845 0.6147 0.63   0.64   0.6465\n",
      " 0.6587]\n",
      "step: 10 \ttraining acc: [0.20583333 0.30333333 0.32458333 0.33416667 0.33375    0.33458333]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.15875]\n",
      "step: 20 \ttraining acc: [0.1925     0.3        0.325      0.3325     0.33041667 0.33458333]\n",
      "step: 20 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.15]\n",
      "step: 30 \ttraining acc: [0.20125    0.29458333 0.31041667 0.31166667 0.31458333 0.31458333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13208333]\n",
      "step: 40 \ttraining acc: [0.20208333 0.28666667 0.29708333 0.30375    0.30791667 0.30791667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.12833333]\n",
      "step: 50 \ttraining acc: [0.24       0.30375    0.32291667 0.33416667 0.33666667 0.33583333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15583333]\n",
      "step: 60 \ttraining acc: [0.21166667 0.29916667 0.32625    0.325      0.32666667 0.32833333]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.13625]\n",
      "Test acc: [0.1946 0.2527 0.2673 0.272  0.2754 0.2751 0.2756 0.2769 0.278  0.2776\n",
      " 0.279 ]\n",
      "Test acc_adv: [0.03   0.0771 0.1156 0.1392 0.1522 0.1624 0.1719 0.1757 0.1791 0.1813\n",
      " 0.1831]\n",
      "Test acc_adv_prior: [0.1536 0.3057 0.4277 0.51   0.5464 0.585  0.617  0.629  0.6396 0.6504\n",
      " 0.6514]\n",
      "step: 70 \ttraining acc: [0.20791667 0.3175     0.33541667 0.3475     0.34875    0.34375   ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16458333]\n",
      "step: 80 \ttraining acc: [0.20708333 0.26958333 0.29791667 0.30041667 0.3075     0.3125    ]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.13625]\n",
      "step: 90 \ttraining acc: [0.20458333 0.3375     0.36083333 0.365      0.36833333 0.37125   ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19208333]\n",
      "step: 100 \ttraining acc: [0.185      0.32041667 0.34958333 0.35666667 0.3625     0.36416667]\n",
      "step: 100 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.17125]\n",
      "step: 110 \ttraining acc: [0.21958333 0.34083333 0.355      0.35875    0.36083333 0.36      ]\n",
      "step: 110 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.17]\n",
      "step: 120 \ttraining acc: [0.205      0.31541667 0.33833333 0.34416667 0.34708333 0.34916667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17333333]\n",
      "Test acc: [0.2068 0.2468 0.267  0.2708 0.2742 0.276  0.2769 0.2769 0.2776 0.2795\n",
      " 0.2788]\n",
      "Test acc_adv: [0.04614 0.0895  0.1263  0.1483  0.1636  0.1731  0.1781  0.181   0.1847\n",
      " 0.1873  0.1885 ]\n",
      "Test acc_adv_prior: [0.2213 0.353  0.4648 0.544  0.5913 0.623  0.643  0.653  0.663  0.6665\n",
      " 0.6743]\n",
      "step: 0 \ttraining acc: [0.19833333 0.29583333 0.33875    0.34083333 0.34333333 0.34875   ]\n",
      "step: 0 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1725]\n",
      "Test acc: [0.2021 0.2466 0.2666 0.2754 0.2776 0.279  0.279  0.2793 0.28   0.2795\n",
      " 0.28  ]\n",
      "Test acc_adv: [0.04413 0.08136 0.11426 0.1412  0.1625  0.1719  0.1772  0.1816  0.1862\n",
      " 0.1884  0.19   ]\n",
      "Test acc_adv_prior: [0.2118 0.3274 0.428  0.5093 0.5806 0.612  0.63   0.646  0.6606 0.6685\n",
      " 0.672 ]\n",
      "step: 10 \ttraining acc: [0.20166667 0.31708333 0.34541667 0.34833333 0.34708333 0.34791667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18166667]\n",
      "step: 20 \ttraining acc: [0.20625    0.31958333 0.34625    0.35791667 0.36291667 0.36333333]\n",
      "step: 20 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1775]\n",
      "step: 30 \ttraining acc: [0.21458333 0.32291667 0.3375     0.34333333 0.35041667 0.34875   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16916667]\n",
      "step: 40 \ttraining acc: [0.19791667 0.31791667 0.33916667 0.34625    0.34458333 0.34875   ]\n",
      "step: 40 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1675]\n",
      "step: 50 \ttraining acc: [0.19541667 0.31291667 0.33291667 0.32916667 0.32666667 0.33083333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16583333]\n",
      "step: 60 \ttraining acc: [0.1875     0.30916667 0.335      0.33875    0.34041667 0.34333333]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17416667]\n",
      "Test acc: [0.1895 0.2458 0.2693 0.278  0.2798 0.2808 0.28   0.2812 0.283  0.2827\n",
      " 0.2837]\n",
      "Test acc_adv: [0.0316  0.0789  0.12067 0.1486  0.1652  0.1758  0.1802  0.1833  0.1854\n",
      " 0.187   0.1888 ]\n",
      "Test acc_adv_prior: [0.1708 0.3223 0.4456 0.533  0.588  0.6245 0.64   0.646  0.6494 0.6567\n",
      " 0.6597]\n",
      "step: 70 \ttraining acc: [0.2        0.31541667 0.35       0.3575     0.36083333 0.36208333]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17083333]\n",
      "step: 80 \ttraining acc: [0.22166667 0.31375    0.32916667 0.33041667 0.33125    0.335     ]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.17375]\n",
      "step: 90 \ttraining acc: [0.19708333 0.32       0.3475     0.35291667 0.35625    0.35625   ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17291667]\n",
      "step: 100 \ttraining acc: [0.20583333 0.29791667 0.33416667 0.34541667 0.35166667 0.35125   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16916667]\n",
      "step: 110 \ttraining acc: [0.20708333 0.29875    0.32375    0.33208333 0.33541667 0.33833333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17416667]\n",
      "step: 120 \ttraining acc: [0.19916667 0.28458333 0.31166667 0.315      0.31625    0.31666667]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.14875]\n",
      "Test acc: [0.1945 0.2476 0.267  0.2732 0.2764 0.2786 0.2778 0.2786 0.278  0.2776\n",
      " 0.2783]\n",
      "Test acc_adv: [0.0668  0.09705 0.1321  0.1534  0.1676  0.174   0.179   0.1841  0.187\n",
      " 0.1895  0.1921 ]\n",
      "Test acc_adv_prior: [0.3315 0.3867 0.4907 0.5547 0.603  0.62   0.6406 0.6597 0.672  0.679\n",
      " 0.6865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.19375    0.3025     0.32541667 0.33041667 0.34041667 0.34166667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17708333]\n",
      "Test acc: [0.2007 0.2568 0.2751 0.277  0.2769 0.2793 0.2793 0.281  0.281  0.2827\n",
      " 0.2854]\n",
      "Test acc_adv: [0.04706 0.08624 0.1305  0.1594  0.1708  0.1768  0.1838  0.187   0.1891\n",
      " 0.1914  0.192  ]\n",
      "Test acc_adv_prior: [0.2244 0.334  0.4712 0.5713 0.612  0.6255 0.652  0.661  0.6685 0.6743\n",
      " 0.6714]\n",
      "step: 10 \ttraining acc: [0.18208333 0.30916667 0.33291667 0.34791667 0.34875    0.35083333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17541667]\n",
      "step: 20 \ttraining acc: [0.1975     0.29375    0.32583333 0.34166667 0.33958333 0.34125   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15833333]\n",
      "step: 30 \ttraining acc: [0.20375    0.29583333 0.33041667 0.35041667 0.35458333 0.35833333]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17541667]\n",
      "step: 40 \ttraining acc: [0.2075     0.3025     0.31625    0.32208333 0.32833333 0.335     ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16083333]\n",
      "step: 50 \ttraining acc: [0.195      0.28958333 0.305      0.30916667 0.31125    0.31541667]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.14125]\n",
      "step: 60 \ttraining acc: [0.2        0.32125    0.35625    0.36625    0.36958333 0.37416667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18833333]\n",
      "Test acc: [0.2001 0.2427 0.2683 0.277  0.2798 0.279  0.281  0.2815 0.282  0.2827\n",
      " 0.2837]\n",
      "Test acc_adv: [0.0744 0.0996 0.1306 0.1516 0.1617 0.1714 0.1781 0.1835 0.186  0.189\n",
      " 0.19  ]\n",
      "Test acc_adv_prior: [0.3655 0.4055 0.4795 0.5405 0.5728 0.611  0.6313 0.653  0.6626 0.668\n",
      " 0.6714]\n",
      "step: 70 \ttraining acc: [0.21041667 0.30708333 0.3425     0.34791667 0.3525     0.35      ]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18166667]\n",
      "step: 80 \ttraining acc: [0.18625    0.28916667 0.31875    0.32875    0.33333333 0.33416667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14666667]\n",
      "step: 90 \ttraining acc: [0.22       0.335      0.34958333 0.35125    0.35125    0.35333333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16333333]\n",
      "step: 100 \ttraining acc: [0.19333333 0.29625    0.31708333 0.33125    0.33583333 0.345     ]\n",
      "step: 100 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.175]\n",
      "step: 110 \ttraining acc: [0.20541667 0.29958333 0.32708333 0.33458333 0.33833333 0.33833333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16708333]\n",
      "step: 120 \ttraining acc: [0.20458333 0.3075     0.32875    0.32958333 0.33125    0.32916667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15916667]\n",
      "Test acc: [0.2017 0.2563 0.2795 0.2837 0.2847 0.2861 0.2866 0.2869 0.2874 0.2874\n",
      " 0.2886]\n",
      "Test acc_adv: [0.05533 0.0959  0.1293  0.1537  0.1646  0.1746  0.1802  0.1835  0.1862\n",
      " 0.1885  0.1906 ]\n",
      "Test acc_adv_prior: [0.2666 0.3645 0.46   0.5366 0.5693 0.602  0.622  0.6333 0.641  0.649\n",
      " 0.654 ]\n",
      "step: 0 \ttraining acc: [0.20125    0.30291667 0.3225     0.32625    0.32875    0.32541667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15708333]\n",
      "Test acc: [0.2009 0.2578 0.2742 0.2756 0.2803 0.2805 0.28   0.2827 0.2854 0.2869\n",
      " 0.2878]\n",
      "Test acc_adv: [0.04   0.0864 0.1299 0.1555 0.1697 0.1798 0.1843 0.1879 0.19   0.1918\n",
      " 0.1927]\n",
      "Test acc_adv_prior: [0.1855 0.3315 0.466  0.5566 0.5996 0.638  0.655  0.661  0.6616 0.664\n",
      " 0.665 ]\n",
      "step: 10 \ttraining acc: [0.21333333 0.32291667 0.35375    0.36083333 0.3625     0.36416667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19041667]\n",
      "step: 20 \ttraining acc: [0.1975     0.3275     0.35541667 0.35791667 0.35583333 0.3575    ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17833333]\n",
      "step: 30 \ttraining acc: [0.21416667 0.31916667 0.33833333 0.34458333 0.34458333 0.34583333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.16875]\n",
      "step: 40 \ttraining acc: [0.1775     0.28833333 0.33541667 0.34583333 0.34666667 0.34833333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18333333]\n",
      "step: 50 \ttraining acc: [0.19625    0.31458333 0.36375    0.37791667 0.38041667 0.3825    ]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19708333]\n",
      "step: 60 \ttraining acc: [0.18791667 0.28916667 0.3075     0.315      0.31916667 0.31666667]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14791667]\n",
      "Test acc: [0.2062 0.2598 0.2793 0.2834 0.2847 0.2864 0.288  0.288  0.289  0.2896\n",
      " 0.2913]\n",
      "Test acc_adv: [0.05106 0.1039  0.1405  0.1619  0.1733  0.1805  0.186   0.1887  0.1909\n",
      " 0.1926  0.1952 ]\n",
      "Test acc_adv_prior: [0.2416 0.389  0.498  0.5703 0.609  0.63   0.6465 0.6543 0.657  0.662\n",
      " 0.666 ]\n",
      "step: 70 \ttraining acc: [0.19833333 0.3        0.34291667 0.35416667 0.35458333 0.35291667]\n",
      "step: 70 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.18]\n",
      "step: 80 \ttraining acc: [0.21625    0.31083333 0.33541667 0.34291667 0.34916667 0.34958333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17041667]\n",
      "step: 90 \ttraining acc: [0.21041667 0.32916667 0.35541667 0.36041667 0.35958333 0.35958333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17458333]\n",
      "step: 100 \ttraining acc: [0.18958333 0.32708333 0.35583333 0.36666667 0.36791667 0.37      ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18041667]\n",
      "step: 110 \ttraining acc: [0.19791667 0.29958333 0.33041667 0.33666667 0.34208333 0.34208333]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17208333]\n",
      "step: 120 \ttraining acc: [0.20333333 0.32291667 0.34708333 0.35291667 0.35083333 0.35333333]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15916667]\n",
      "Test acc: [0.192  0.2642 0.2822 0.2876 0.2896 0.2908 0.2915 0.293  0.293  0.2935\n",
      " 0.2937]\n",
      "Test acc_adv: [0.02974 0.09296 0.1376  0.1598  0.1725  0.1803  0.1849  0.187   0.1898\n",
      " 0.191   0.1925 ]\n",
      "Test acc_adv_prior: [0.1512 0.341  0.4836 0.5513 0.5923 0.616  0.6294 0.633  0.6426 0.6465\n",
      " 0.6504]\n",
      "step: 0 \ttraining acc: [0.18625    0.32416667 0.35458333 0.36166667 0.36625    0.36458333]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18583333]\n",
      "Test acc: [0.1968 0.251  0.279  0.2874 0.2915 0.2915 0.2937 0.293  0.2937 0.2935\n",
      " 0.2932]\n",
      "Test acc_adv: [0.03934 0.0908  0.1421  0.1652  0.1753  0.1835  0.1864  0.1896  0.1925\n",
      " 0.1948  0.1953 ]\n",
      "Test acc_adv_prior: [0.1866 0.3555 0.505  0.5713 0.5938 0.6245 0.63   0.642  0.652  0.6597\n",
      " 0.661 ]\n",
      "step: 10 \ttraining acc: [0.17916667 0.32375    0.36041667 0.35833333 0.35875    0.35791667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18041667]\n",
      "step: 20 \ttraining acc: [0.18041667 0.32458333 0.36       0.36458333 0.37208333 0.37583333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17458333]\n",
      "step: 30 \ttraining acc: [0.21458333 0.32208333 0.33875    0.34833333 0.34916667 0.34875   ]\n",
      "step: 30 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.16]\n",
      "step: 40 \ttraining acc: [0.20041667 0.34833333 0.37       0.37375    0.37666667 0.37416667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19458333]\n",
      "step: 50 \ttraining acc: [0.19291667 0.34583333 0.36958333 0.38708333 0.38958333 0.38916667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18791667]\n",
      "step: 60 \ttraining acc: [0.19208333 0.32041667 0.3625     0.37166667 0.37458333 0.37375   ]\n",
      "step: 60 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.18875]\n",
      "Test acc: [0.2054 0.262  0.2822 0.2913 0.294  0.296  0.2966 0.2957 0.296  0.2954\n",
      " 0.2969]\n",
      "Test acc_adv: [0.0699 0.1108 0.1466 0.168  0.1783 0.1844 0.1863 0.1896 0.1941 0.196\n",
      " 0.1964]\n",
      "Test acc_adv_prior: [0.3384 0.4163 0.518  0.576  0.605  0.622  0.6245 0.637  0.653  0.661\n",
      " 0.6597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 70 \ttraining acc: [0.20375    0.3075     0.32416667 0.335      0.33375    0.33666667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16791667]\n",
      "step: 80 \ttraining acc: [0.18958333 0.32583333 0.36291667 0.37666667 0.37666667 0.37583333]\n",
      "step: 80 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.19625]\n",
      "step: 90 \ttraining acc: [0.21333333 0.31333333 0.33833333 0.34666667 0.34833333 0.35083333]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16583333]\n",
      "step: 100 \ttraining acc: [0.2225     0.31875    0.33333333 0.33666667 0.34208333 0.34375   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15708333]\n",
      "step: 110 \ttraining acc: [0.19083333 0.32333333 0.34583333 0.3475     0.35083333 0.34875   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16541667]\n",
      "step: 120 \ttraining acc: [0.195      0.3125     0.34666667 0.34666667 0.34958333 0.34958333]\n",
      "step: 120 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.16125]\n",
      "Test acc: [0.1996 0.265  0.2837 0.291  0.2913 0.2917 0.2922 0.2925 0.2937 0.2944\n",
      " 0.2942]\n",
      "Test acc_adv: [0.056   0.10706 0.1447  0.1666  0.1764  0.1815  0.185   0.1866  0.1881\n",
      " 0.1892  0.1895 ]\n",
      "Test acc_adv_prior: [0.2761 0.4048 0.5083 0.57   0.5996 0.6177 0.6304 0.635  0.6377 0.638\n",
      " 0.64  ]\n",
      "step: 0 \ttraining acc: [0.17166667 0.28375    0.31791667 0.32791667 0.33458333 0.33625   ]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15958333]\n",
      "Test acc: [0.2054 0.26   0.2805 0.2893 0.2905 0.292  0.2937 0.295  0.2964 0.2961\n",
      " 0.2966]\n",
      "Test acc_adv: [0.04852 0.10504 0.1395  0.1605  0.1724  0.1794  0.1832  0.1868  0.1876\n",
      " 0.189   0.1898 ]\n",
      "Test acc_adv_prior: [0.2363 0.3994 0.4946 0.549  0.59   0.609  0.618  0.626  0.627  0.633\n",
      " 0.635 ]\n",
      "step: 10 \ttraining acc: [0.19625    0.31833333 0.36125    0.37166667 0.37291667 0.3725    ]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17791667]\n",
      "step: 20 \ttraining acc: [0.18208333 0.3        0.34875    0.35958333 0.36333333 0.36625   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17916667]\n",
      "step: 30 \ttraining acc: [0.2        0.31291667 0.34416667 0.35291667 0.35958333 0.36416667]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16833333]\n",
      "step: 40 \ttraining acc: [0.1975     0.31958333 0.34583333 0.35666667 0.36291667 0.36208333]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17333333]\n",
      "step: 50 \ttraining acc: [0.21       0.33375    0.34833333 0.35416667 0.35416667 0.35666667]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18083333]\n",
      "step: 60 \ttraining acc: [0.195      0.32       0.3525     0.36958333 0.37333333 0.375     ]\n",
      "step: 60 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18208333]\n",
      "Test acc: [0.1985 0.2534 0.285  0.2908 0.2937 0.2932 0.2942 0.2942 0.2944 0.2942\n",
      " 0.294 ]\n",
      "Test acc_adv: [0.05533 0.09894 0.1421  0.1643  0.1772  0.1824  0.1869  0.19    0.1912\n",
      " 0.1921  0.1917 ]\n",
      "Test acc_adv_prior: [0.2751 0.3828 0.494  0.5615 0.5977 0.6167 0.6313 0.6416 0.6465 0.652\n",
      " 0.651 ]\n",
      "step: 70 \ttraining acc: [0.18041667 0.30958333 0.33       0.34458333 0.34875    0.35166667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16541667]\n",
      "step: 80 \ttraining acc: [0.19916667 0.29458333 0.32083333 0.32541667 0.32375    0.32208333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14583333]\n",
      "step: 90 \ttraining acc: [0.20208333 0.32666667 0.35833333 0.36625    0.37041667 0.37166667]\n",
      "step: 90 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.19375]\n",
      "step: 100 \ttraining acc: [0.19208333 0.34583333 0.35666667 0.35833333 0.36125    0.36166667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16666667]\n",
      "step: 110 \ttraining acc: [0.20416667 0.31208333 0.33791667 0.34083333 0.34375    0.34375   ]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16583333]\n",
      "step: 120 \ttraining acc: [0.17958333 0.31583333 0.35958333 0.36291667 0.37       0.3725    ]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17833333]\n",
      "Test acc: [0.208  0.2693 0.297  0.3    0.2974 0.2986 0.3008 0.3008 0.301  0.3\n",
      " 0.2998]\n",
      "Test acc_adv: [0.06226 0.1085  0.1506  0.1703  0.1827  0.186   0.1898  0.192   0.1919\n",
      " 0.1932  0.1934 ]\n",
      "Test acc_adv_prior: [0.297  0.3962 0.502  0.565  0.6123 0.618  0.627  0.6333 0.6313 0.6367\n",
      " 0.638 ]\n",
      "step: 0 \ttraining acc: [0.185      0.32083333 0.35291667 0.35625    0.36625    0.36916667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17041667]\n",
      "Test acc: [0.1963 0.2705 0.2874 0.2947 0.2993 0.3013 0.302  0.3003 0.2998 0.2998\n",
      " 0.2986]\n",
      "Test acc_adv: [0.04132 0.1003  0.1439  0.1688  0.1771  0.1831  0.1863  0.1897  0.1919\n",
      " 0.1934  0.1945 ]\n",
      "Test acc_adv_prior: [0.2037 0.365  0.4978 0.5664 0.585  0.602  0.612  0.6294 0.6377 0.64\n",
      " 0.6465]\n",
      "step: 10 \ttraining acc: [0.18708333 0.31291667 0.34125    0.34875    0.35       0.35041667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17291667]\n",
      "step: 20 \ttraining acc: [0.22708333 0.32958333 0.33875    0.33833333 0.34208333 0.345     ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16041667]\n",
      "step: 30 \ttraining acc: [0.19166667 0.29833333 0.32125    0.32791667 0.32625    0.32958333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.15625]\n",
      "step: 40 \ttraining acc: [0.1725     0.29708333 0.32166667 0.32875    0.33041667 0.33375   ]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14916667]\n",
      "step: 50 \ttraining acc: [0.20041667 0.32791667 0.35125    0.35666667 0.35833333 0.35583333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17541667]\n",
      "step: 60 \ttraining acc: [0.19625    0.32708333 0.33958333 0.33958333 0.34291667 0.34583333]\n",
      "step: 60 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1575]\n",
      "Test acc: [0.2056 0.272  0.296  0.3005 0.304  0.3057 0.308  0.3057 0.3064 0.3064\n",
      " 0.307 ]\n",
      "Test acc_adv: [0.04068 0.1028  0.1506  0.1708  0.1798  0.1846  0.1888  0.1919  0.1918\n",
      " 0.1926  0.1932 ]\n",
      "Test acc_adv_prior: [0.188  0.3743 0.5083 0.566  0.5894 0.5996 0.6094 0.6235 0.6196 0.624\n",
      " 0.6255]\n",
      "step: 70 \ttraining acc: [0.19625    0.30375    0.34       0.35291667 0.35583333 0.35958333]\n",
      "step: 70 \ttraining acc_adv: [0.    0.    0.    0.    0.    0.165]\n",
      "step: 80 \ttraining acc: [0.185      0.3125     0.33791667 0.35291667 0.36291667 0.36458333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18333333]\n",
      "step: 90 \ttraining acc: [0.17916667 0.33166667 0.35166667 0.36333333 0.365      0.3675    ]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18833333]\n",
      "step: 100 \ttraining acc: [0.20833333 0.3275     0.35833333 0.36541667 0.36708333 0.36875   ]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18791667]\n",
      "step: 110 \ttraining acc: [0.19791667 0.3425     0.37416667 0.38041667 0.38833333 0.39125   ]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1875]\n",
      "step: 120 \ttraining acc: [0.19291667 0.33958333 0.35       0.35083333 0.35166667 0.35541667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16916667]\n",
      "Test acc: [0.1906 0.2766 0.294  0.2974 0.3003 0.3003 0.3008 0.3015 0.3018 0.302\n",
      " 0.3022]\n",
      "Test acc_adv: [0.02814 0.1056  0.1503  0.1707  0.1796  0.1844  0.1884  0.1898  0.1903\n",
      " 0.1903  0.1918 ]\n",
      "Test acc_adv_prior: [0.1453 0.379  0.5073 0.569  0.5933 0.607  0.618  0.6226 0.624  0.624\n",
      " 0.631 ]\n",
      "step: 0 \ttraining acc: [0.19291667 0.30541667 0.32166667 0.3225     0.32625    0.32625   ]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.15625]\n",
      "Test acc: [0.1989 0.2798 0.297  0.301  0.2996 0.2979 0.298  0.2988 0.2996 0.3003\n",
      " 0.301 ]\n",
      "Test acc_adv: [0.0468 0.1149 0.1514 0.1688 0.1783 0.1827 0.1858 0.1887 0.1896 0.1893\n",
      " 0.191 ]\n",
      "Test acc_adv_prior: [0.2258 0.4023 0.5024 0.5547 0.588  0.605  0.6143 0.6226 0.6245 0.623\n",
      " 0.6274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 \ttraining acc: [0.205      0.36708333 0.39208333 0.3975     0.39625    0.39541667]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18791667]\n",
      "step: 20 \ttraining acc: [0.18458333 0.31708333 0.34583333 0.35125    0.35291667 0.35208333]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17083333]\n",
      "step: 30 \ttraining acc: [0.20458333 0.32541667 0.35375    0.3675     0.36458333 0.36083333]\n",
      "step: 30 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.18875]\n",
      "step: 40 \ttraining acc: [0.18958333 0.32833333 0.36541667 0.37583333 0.38291667 0.38666667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18833333]\n",
      "step: 50 \ttraining acc: [0.21041667 0.32708333 0.35083333 0.3575     0.35875    0.35833333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18458333]\n",
      "step: 60 \ttraining acc: [0.19708333 0.31291667 0.34708333 0.35583333 0.36083333 0.36291667]\n",
      "step: 60 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.14]\n",
      "Test acc: [0.1989 0.2659 0.294  0.3057 0.3062 0.3062 0.3098 0.3105 0.3113 0.31\n",
      " 0.3105]\n",
      "Test acc_adv: [0.05853 0.12494 0.1549  0.1722  0.179   0.183   0.1848  0.1855  0.1877\n",
      " 0.1863  0.1885 ]\n",
      "Test acc_adv_prior: [0.295  0.469  0.5215 0.559  0.5776 0.5913 0.591  0.593  0.5986 0.5986\n",
      " 0.6035]\n",
      "step: 70 \ttraining acc: [0.18333333 0.31416667 0.34166667 0.35541667 0.35208333 0.355     ]\n",
      "step: 70 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.15375]\n",
      "step: 80 \ttraining acc: [0.19166667 0.36291667 0.38       0.39166667 0.39458333 0.39041667]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19541667]\n",
      "step: 90 \ttraining acc: [0.17708333 0.325      0.35541667 0.36916667 0.37541667 0.37791667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18458333]\n",
      "step: 100 \ttraining acc: [0.19791667 0.275      0.29708333 0.31416667 0.31541667 0.31458333]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.13291667]\n",
      "step: 110 \ttraining acc: [0.21333333 0.34041667 0.35708333 0.35875    0.36083333 0.36291667]\n",
      "step: 110 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16958333]\n",
      "step: 120 \ttraining acc: [0.20125    0.32958333 0.3475     0.35708333 0.35791667 0.35875   ]\n",
      "step: 120 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1575]\n",
      "Test acc: [0.2017 0.265  0.2974 0.3037 0.3079 0.3127 0.3123 0.3132 0.3132 0.3118\n",
      " 0.311 ]\n",
      "Test acc_adv: [0.06174 0.11096 0.154   0.1746  0.1805  0.1846  0.1865  0.187   0.1875\n",
      " 0.1879  0.1885 ]\n",
      "Test acc_adv_prior: [0.2969 0.4055 0.513  0.5703 0.5825 0.5845 0.593  0.5947 0.594  0.599\n",
      " 0.603 ]\n",
      "step: 0 \ttraining acc: [0.20958333 0.35375    0.39291667 0.39916667 0.39708333 0.40333333]\n",
      "step: 0 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.19375]\n",
      "Test acc: [0.2051 0.267  0.2932 0.3013 0.3076 0.3093 0.3066 0.308  0.3096 0.3096\n",
      " 0.311 ]\n",
      "Test acc_adv: [0.072  0.1219 0.161  0.1774 0.1825 0.1879 0.1876 0.1888 0.1884 0.1879\n",
      " 0.1873]\n",
      "Test acc_adv_prior: [0.3455 0.4424 0.5454 0.5884 0.591  0.6035 0.6055 0.607  0.6016 0.599\n",
      " 0.595 ]\n",
      "step: 10 \ttraining acc: [0.18708333 0.33125    0.35625    0.36541667 0.36375    0.36125   ]\n",
      "step: 10 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.16375]\n",
      "step: 20 \ttraining acc: [0.19875    0.31958333 0.35333333 0.3575     0.35583333 0.36125   ]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15541667]\n",
      "step: 30 \ttraining acc: [0.20083333 0.35166667 0.38208333 0.39375    0.40375    0.40375   ]\n",
      "step: 30 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19458333]\n",
      "step: 40 \ttraining acc: [0.18291667 0.33833333 0.36416667 0.36541667 0.37       0.37041667]\n",
      "step: 40 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.18375]\n",
      "step: 50 \ttraining acc: [0.21041667 0.32583333 0.35541667 0.36       0.36416667 0.36583333]\n",
      "step: 50 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16833333]\n",
      "step: 60 \ttraining acc: [0.21       0.33125    0.35       0.3475     0.34875    0.35083333]\n",
      "step: 60 \ttraining acc_adv: [0.   0.   0.   0.   0.   0.15]\n",
      "Test acc: [0.201  0.2795 0.3062 0.3137 0.3154 0.3132 0.3135 0.3147 0.3147 0.3147\n",
      " 0.3157]\n",
      "Test acc_adv: [0.0564  0.12134 0.1608  0.1796  0.1877  0.1888  0.1902  0.1908  0.1909\n",
      " 0.1925  0.1925 ]\n",
      "Test acc_adv_prior: [0.276  0.43   0.5176 0.568  0.59   0.5957 0.599  0.5986 0.599  0.606\n",
      " 0.6025]\n",
      "step: 70 \ttraining acc: [0.185      0.295      0.32875    0.33666667 0.33916667 0.33916667]\n",
      "step: 70 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.14916667]\n",
      "step: 80 \ttraining acc: [0.21458333 0.33333333 0.35875    0.36541667 0.36916667 0.37083333]\n",
      "step: 80 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17208333]\n",
      "step: 90 \ttraining acc: [0.21625    0.36208333 0.3925     0.39416667 0.4        0.40166667]\n",
      "step: 90 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.18958333]\n",
      "step: 100 \ttraining acc: [0.20416667 0.34458333 0.36583333 0.3725     0.38041667 0.38041667]\n",
      "step: 100 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.17833333]\n",
      "step: 110 \ttraining acc: [0.19666667 0.31583333 0.35       0.35125    0.36125    0.3675    ]\n",
      "step: 110 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1675]\n",
      "step: 120 \ttraining acc: [0.195      0.32416667 0.33625    0.34333333 0.34458333 0.34291667]\n",
      "step: 120 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.15333333]\n",
      "Test acc: [0.2041 0.2798 0.3093 0.3125 0.3167 0.3184 0.318  0.3203 0.321  0.3203\n",
      " 0.3203]\n",
      "Test acc_adv: [0.06665 0.1383  0.1694  0.1865  0.1932  0.1941  0.1948  0.1946  0.1937\n",
      " 0.1946  0.1948 ]\n",
      "Test acc_adv_prior: [0.324  0.4875 0.5444 0.5874 0.6006 0.6    0.601  0.598  0.5938 0.597\n",
      " 0.598 ]\n",
      "step: 0 \ttraining acc: [0.21166667 0.345      0.36791667 0.37708333 0.37666667 0.37291667]\n",
      "step: 0 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16083333]\n",
      "Test acc: [0.1978 0.2705 0.3018 0.3127 0.3118 0.3132 0.3145 0.3157 0.3167 0.317\n",
      " 0.318 ]\n",
      "Test acc_adv: [0.05893 0.1348  0.162   0.1793  0.1887  0.1897  0.1914  0.1925  0.1941\n",
      " 0.194   0.1953 ]\n",
      "Test acc_adv_prior: [0.2922 0.4924 0.5283 0.564  0.596  0.5967 0.599  0.5996 0.6016 0.5996\n",
      " 0.6025]\n",
      "step: 10 \ttraining acc: [0.195      0.37166667 0.40541667 0.41208333 0.42166667 0.42833333]\n",
      "step: 10 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.19916667]\n",
      "step: 20 \ttraining acc: [0.18791667 0.31833333 0.35208333 0.35958333 0.36041667 0.36041667]\n",
      "step: 20 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16166667]\n",
      "step: 30 \ttraining acc: [0.18875    0.35       0.37708333 0.38625    0.38958333 0.39166667]\n",
      "step: 30 \ttraining acc_adv: [0.     0.     0.     0.     0.     0.1875]\n",
      "step: 40 \ttraining acc: [0.20958333 0.35666667 0.37541667 0.37916667 0.38625    0.38541667]\n",
      "step: 40 \ttraining acc_adv: [0.         0.         0.         0.         0.         0.16583333]\n",
      "step: 50 \ttraining acc: [0.2025     0.3575     0.38625    0.3875     0.38583333 0.38708333]\n",
      "step: 50 \ttraining acc_adv: [0.      0.      0.      0.      0.      0.18625]\n"
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "import time\n",
    "\n",
    "#from ANIP import Meta\n",
    "#from metafgsmanil import Meta\n",
    "#from metafgsm import Meta\n",
    "#from MAMLMeta import Meta\n",
    "#from meta import Meta\n",
    "#from Adv_Quer import Meta\n",
    "#from metafgsmnewnew import Meta\n",
    "from metapgd import Meta\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('../run-imgsz28-4000/pgd-metalr=0.003-advlr=0.0002', comment='pgd-metalr=0.003-advlr=0.0002')\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0] \n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "def main():\n",
    "    \n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "    '''\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 5 * 5])\n",
    "    ]\n",
    "    '''\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 2 * 2])\n",
    "    ]\n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    maml = Meta(args, config, device).to(device)\n",
    "    \n",
    "    \n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    #filename = 'mamlfgsmeps4_2.pt'\n",
    "    filename = 'mamlfgsmeps2_8.pt'\n",
    "    #maml = Meta(args, config).to(device)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        maml.net.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "    \n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('../../dataset/', mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                        k_query=args.k_qry,\n",
    "                        batchsz=4000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../../dataset/', mode='test', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "    tot_step = -args.task_num\n",
    "    #adv_loss_on = True\n",
    "    for epoch in range(100):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db): # 0~124 -> batch 32일 때\n",
    "            tot_step = tot_step + args.task_num\n",
    "            '''\n",
    "            if step == 1:\n",
    "                t = time.perf_counter()\n",
    "            if step == 499:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "            if step == 501:\n",
    "                t = time.perf_counter()\n",
    "            if step == 999:\n",
    "                ExecTime = time.perf_counter() - t\n",
    "                print(ExecTime)\n",
    "            '''\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs, accs_adv, loss_q, loss_q_adv = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "                print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "                writer.add_scalar(\"acc/train\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/train\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"loss/train\", loss_q,tot_step)\n",
    "                writer.add_scalar(\"loss_adv/train\", loss_q_adv,tot_step)\n",
    "                state = {'epoch': epoch, 'step': step, 'state_dict': maml.net.state_dict()}\n",
    "                torch.save(state, 'mamlfgsmeps4_2.pt')\n",
    "            \n",
    "            if step % 60 == 0:  # evaluation -> 학습에는 전혀 영향을 주지 않음, copy network를 사용하므로\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                accsadv_all_test = []\n",
    "                accsadvpr_all_test = []\n",
    "                loss_all_test = []\n",
    "                loss_adv_all_test = []\n",
    "                \n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    accs, accs_adv, accs_adv_prior, loss_q, loss_q_adv = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "                    accsadv_all_test.append(accs_adv)\n",
    "                    accsadvpr_all_test.append(accs_adv_prior)\n",
    "                    loss_all_test.append(loss_q.item())\n",
    "                    loss_adv_all_test.append(loss_q_adv.item())\n",
    "                    \n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "                loss_q = np.array(loss_all_test).mean()\n",
    "                loss_q_adv = np.array(loss_adv_all_test).mean()\n",
    "                print('Test acc:', accs)\n",
    "                print('Test acc_adv:', accs_adv)\n",
    "                print('Test acc_adv_prior:', accs_adv_prior)\n",
    "                writer.add_scalar(\"acc/test\", accs[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv/test\", accs_adv[-1],tot_step)\n",
    "                writer.add_scalar(\"acc_adv_prior/test\", accs_adv_prior[-1],tot_step)\n",
    "                writer.add_scalar(\"loss/test\", loss_q,tot_step)\n",
    "                writer.add_scalar(\"loss_adv/test\", loss_q_adv,tot_step)\n",
    "                if step==120:\n",
    "                    writer.add_scalar(\"acc/test_epoch\", accs[-1],epoch)\n",
    "                    writer.add_scalar(\"acc_adv/test_epoch\", accs_adv[-1],epoch)\n",
    "                    writer.add_scalar(\"loss/epoch\", loss_q, epoch)\n",
    "                    writer.add_scalar(\"loss_adv/epoch\", loss_q_adv, epoch)\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=60000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=28)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=32)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=0.001) #0.001 - 0.0002 기존\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
